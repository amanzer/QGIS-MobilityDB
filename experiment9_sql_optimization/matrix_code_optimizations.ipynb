{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook : we implement ways of optimizing the code that generates the matrix during the animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# existing solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = ['0', '59', '1', '-180', '-90', '180', '90', '2023-06-01 00:00:00', '1440', 'SECOND', '/home/ali/matrices/60_1', 'mobilitydb', 'processed_data', 'MMSI', 'traj']\n",
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "File used to create the matrices for the time deltas between the begin_frame and end_frame.\n",
    "\n",
    "The matrices are saved in the /home/ali/matrices/ folder.\n",
    "\n",
    "\n",
    "            # arguments :[ \n",
    "            # 0: begin_frame, \n",
    "            # 1: end_frame, \n",
    "            # 2: PERCENTAGE_OF_OBJECTS, \n",
    "            # 3: x_min, 4: y_min, 5: x_max, 6: y_max, \n",
    "            # 7: start_timestamp, \n",
    "            # 8: total_frames, \n",
    "            # 9: granularity, \n",
    "            # 10: matrix_directory_path, \n",
    "            # 11: database_name, \n",
    "            # 12: table_name, \n",
    "            # 13: id_column_name, \n",
    "            # 14: tpoint_column_name]\n",
    "\n",
    "To measure the size of matrices folder : du -sh --block-size=MB matrices            \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from pymeos.db.psycopg import MobilityDB\n",
    "\n",
    "from pymeos import *\n",
    "import os\n",
    "import sys\n",
    "from datetime import timedelta, datetime\n",
    "from pymeos import *\n",
    "import time\n",
    "\n",
    "logs = \"\"\n",
    "now = time.time()\n",
    "\n",
    "\n",
    "args = arguments\n",
    "logs += f\"Args: {args}\\n\"\n",
    "begin_frame = int(args[0])\n",
    "end_frame = int(args[1])\n",
    "TIME_DELTA_SIZE = end_frame - begin_frame + 1\n",
    "PERCENTAGE_OF_OBJECTS = float(args[2])\n",
    "\n",
    "\n",
    "SRID = 4326\n",
    "\n",
    "\n",
    "DATABASE_NAME = args[11]\n",
    "TPOINT_TABLE_NAME = args[12]\n",
    "TPOINT_ID_COLUMN_NAME = args[13]\n",
    "TPOINT_COLUMN_NAME = args[14]\n",
    "\n",
    "\n",
    "\n",
    "class Database_connector:\n",
    "    \"\"\"\n",
    "    Singleton class used to connect to the MobilityDB database.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        try: \n",
    "            connection_params = {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 5432,\n",
    "            \"dbname\": DATABASE_NAME,\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"postgres\"\n",
    "            }\n",
    "            self.table_name = TPOINT_TABLE_NAME\n",
    "            self.id_column_name = TPOINT_ID_COLUMN_NAME\n",
    "            self.tpoint_column_name = TPOINT_COLUMN_NAME               \n",
    "            self.connection = MobilityDB.connect(**connection_params)\n",
    "\n",
    "            self.cursor = self.connection.cursor()\n",
    "\n",
    "            self.cursor.execute(f\"SELECT {self.id_column_name} FROM public.{self.table_name};\")\n",
    "            self.ids_list = self.cursor.fetchall()\n",
    "            self.ids_list = self.ids_list[:int(len(self.ids_list)*PERCENTAGE_OF_OBJECTS)]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "  \n",
    "    def get_subset_of_tpoints(self, pstart, pend, xmin, ymin, xmax, ymax):\n",
    "        \"\"\"\n",
    "        For each object in the ids_list :\n",
    "            Fetch the subset of the associated Tpoints between the start and end timestamps\n",
    "            contained in the STBOX defined by the xmin, ymin, xmax, ymax.\n",
    "        \"\"\"\n",
    "        try:\n",
    "           \n",
    "            ids_list = [ f\"'{id[0]}'\"  for id in self.ids_list]\n",
    "            ids_str = ', '.join(map(str, ids_list))\n",
    "          \n",
    "            query = f\"\"\"\n",
    "                    SELECT \n",
    "                        atStbox(\n",
    "                            a.{self.tpoint_column_name}::tgeompoint,\n",
    "                            stbox(\n",
    "                                ST_MakeEnvelope(\n",
    "                                    {xmin}, {ymin}, -- xmin, ymin\n",
    "                                    {xmax}, {ymax}, -- xmax, ymax\n",
    "                                    4326 -- SRID\n",
    "                                ),\n",
    "                                tstzspan('[{pstart}, {pend}]')\n",
    "                            )\n",
    "                        )\n",
    "                    FROM public.{self.table_name} as a \n",
    "                    WHERE a.{self.id_column_name} in ({ids_str});\n",
    "                    \"\"\"\n",
    "            self.cursor.execute(query)\n",
    "            # print(query)\n",
    "            rows = self.cursor.fetchall()\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            pass\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close the connection to the MobilityDB database.\n",
    "        \"\"\"\n",
    "        self.cursor.close()\n",
    "        self.connection.close()\n",
    "\n",
    "\n",
    "MATRIX_DIRECTORY_PATH = \"/home/ali/matrices\"\n",
    "file_name = f\"{args[10]}/matrix_{begin_frame}.npy\"\n",
    "\n",
    "\n",
    "  \n",
    "Time_granularities = {\n",
    "                    # \"MILLISECOND\" : timedelta(milliseconds=1),\n",
    "                      \"SECOND\" : timedelta(seconds=1),\n",
    "                      \"MINUTE\" : timedelta(minutes=1),\n",
    "                    #   \"HOUR\" : timedelta(hours=1),\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "pymeos_initialize()\n",
    "db = Database_connector()\n",
    "\n",
    "x_min = float(args[3])\n",
    "y_min = float(args[4])\n",
    "x_max = float(args[5])\n",
    "y_max = float(args[6])\n",
    "\n",
    "start_date = args[7]\n",
    "start_date = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "total_frames = int(args[8])\n",
    "GRANULARITY = Time_granularities[args[9]]\n",
    "\n",
    "timestamps = []\n",
    "for i in range(total_frames): \n",
    "    timestamps.append(start_date + i*GRANULARITY)\n",
    "\n",
    "\n",
    "\n",
    "p_start = timestamps[begin_frame]\n",
    "p_end = timestamps[end_frame]\n",
    "# print(p_start, p_end, x_min, y_min, x_max, y_max)\n",
    "now_db = time.time()\n",
    "rows = db.get_subset_of_tpoints(p_start, p_end, x_min, y_min, x_max, y_max)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs += f\"Time to fetch subset of tpoints: {time.time() - now_db} seconds\\n\"\n",
    "        \n",
    "empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "\n",
    "time_ranges = timestamps\n",
    "now = time.time()\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    try:\n",
    "        traj = rows[i][0]\n",
    "        traj = traj.temporal_precision(GRANULARITY) \n",
    "        num_instants = traj.num_instants()\n",
    "        if num_instants == 0:\n",
    "            continue\n",
    "        elif num_instants == 1:\n",
    "            single_timestamp = traj.timestamps()[0].replace(tzinfo=None)\n",
    "            index = time_ranges.index(single_timestamp) - begin_frame\n",
    "            matrix[i][index] = traj.values()[0].wkt\n",
    "        \n",
    "        elif num_instants >= 2:\n",
    "            traj_resampled = traj.temporal_sample(start=time_ranges[0],duration= GRANULARITY)\n",
    "            \n",
    "            start_index = time_ranges.index( traj_resampled.start_timestamp().replace(tzinfo=None) ) - begin_frame\n",
    "            end_index = time_ranges.index( traj_resampled.end_timestamp().replace(tzinfo=None) ) - begin_frame\n",
    "    \n",
    "            trajectory_array = np.array([point.wkt for point in traj_resampled.values()])\n",
    "            matrix[i, start_index:end_index+1] = trajectory_array\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "np.save(file_name, matrix)\n",
    "\n",
    "db.close()\n",
    "pymeos_finalize()\n",
    "total_time = time.time() - now\n",
    "frames_for_30_fps= 30 * total_time\n",
    "print(f\"================================================================     Matrix {begin_frame} created in {total_time} seconds, {frames_for_30_fps} frames for 30 fps animation.\")\n",
    "logs += f\"time to create and fill the matrix {begin_frame}: {total_time} seconds\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving the resampling of trajectories in the database query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to fetch tpoints : 1.8734567165374756 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from pymeos.db.psycopg import MobilityDB\n",
    "\n",
    "from pymeos import *\n",
    "import os\n",
    "import sys\n",
    "from datetime import timedelta, datetime\n",
    "from pymeos import *\n",
    "import time\n",
    "\n",
    "logs = \"\"\n",
    "now = time.time()\n",
    "\n",
    "FPS_DEQUEUE_SIZE = 5 # Length of the dequeue to calculate the average FPS\n",
    "TIME_DELTA_DEQUEUE_SIZE =  10 # Length of the dequeue to keep the keys to keep in the buffer\n",
    "\n",
    "\n",
    "args = sysargs\n",
    "logs += f\"Args: {args}\\n\"\n",
    "begin_frame = int(args[0])\n",
    "end_frame = int(args[1])\n",
    "TIME_DELTA_SIZE = end_frame - begin_frame + 1\n",
    "PERCENTAGE_OF_OBJECTS = float(args[2])\n",
    "\n",
    "\n",
    "SRID = 4326\n",
    "\n",
    "\n",
    "DATABASE_NAME = args[11]\n",
    "TPOINT_TABLE_NAME = args[12]\n",
    "TPOINT_ID_COLUMN_NAME = args[13]\n",
    "TPOINT_COLUMN_NAME = args[14]\n",
    "\n",
    "\n",
    "\n",
    "class Database_connector2:\n",
    "    \"\"\"\n",
    "    Singleton class used to connect to the MobilityDB database.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        try: \n",
    "            connection_params = {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 5432,\n",
    "            \"dbname\": DATABASE_NAME,\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"postgres\"\n",
    "            }\n",
    "            self.table_name = TPOINT_TABLE_NAME\n",
    "            self.id_column_name = TPOINT_ID_COLUMN_NAME\n",
    "            self.tpoint_column_name = TPOINT_COLUMN_NAME               \n",
    "            self.connection = MobilityDB.connect(**connection_params)\n",
    "\n",
    "            self.cursor = self.connection.cursor()\n",
    "\n",
    "            self.cursor.execute(f\"SELECT {self.id_column_name} FROM public.{self.table_name};\")\n",
    "            self.ids_list = self.cursor.fetchall()\n",
    "            self.ids_list = self.ids_list[:int(len(self.ids_list)*PERCENTAGE_OF_OBJECTS)]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "  \n",
    "    def get_subset_of_tpoints(self, pstart, pend, xmin, ymin, xmax, ymax):\n",
    "        \"\"\"\n",
    "        For each object in the ids_list :\n",
    "            Fetch the subset of the associated Tpoints between the start and end timestamps\n",
    "            contained in the STBOX defined by the xmin, ymin, xmax, ymax.\n",
    "        \"\"\"\n",
    "        try:\n",
    "           \n",
    "            ids_list = [ f\"'{id[0]}'\"  for id in self.ids_list]\n",
    "            ids_str = ', '.join(map(str, ids_list))\n",
    "          \n",
    "            query = f\"\"\"\n",
    "                    WITH trajectories as (\n",
    "                    SELECT \n",
    "                        atStbox(\n",
    "                            a.{self.tpoint_column_name}::tgeompoint,\n",
    "                            stbox(\n",
    "                                ST_MakeEnvelope(\n",
    "                                    {xmin}, {ymin}, -- xmin, ymin\n",
    "                                    {xmax}, {ymax}, -- xmax, ymax\n",
    "                                    4326 -- SRID\n",
    "                                ),\n",
    "                                tstzspan('[{pstart}, {pend}]')\n",
    "                            )\n",
    "                        ) as trajectory\n",
    "                    FROM public.{self.table_name} as a \n",
    "                    WHERE a.{self.id_column_name} in ({ids_str}))\n",
    "\n",
    "                    SELECT tsample(trajectory, INTERVAL '1 minute', TIMESTAMP '2023-06-01 00:00:00')  AS resampled_trajectory\n",
    "                        FROM \n",
    "                            trajectories ;\n",
    " \n",
    "                    \"\"\"\n",
    "            self.cursor.execute(query)\n",
    "            # print(query)\n",
    "            rows = self.cursor.fetchall()\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            pass\n",
    "\n",
    "\n",
    "    def get_min_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the min timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            self.cursor.execute(f\"SELECT MIN(startTimestamp({self.tpoint_column_name})) AS earliest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    def get_max_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the max timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.cursor.execute(f\"SELECT MAX(endTimestamp({self.tpoint_column_name})) AS latest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close the connection to the MobilityDB database.\n",
    "        \"\"\"\n",
    "        self.cursor.close()\n",
    "        self.connection.close()\n",
    "\n",
    "\n",
    "MATRIX_DIRECTORY_PATH = \"/home/ali/matrices\"\n",
    "file_name = f\"/home/ali/matrices/matrix_{begin_frame}.npy\"\n",
    "\n",
    "\n",
    "  \n",
    "Time_granularities = {\n",
    "                    # \"MILLISECOND\" : timedelta(milliseconds=1),\n",
    "                      \"SECOND\" : timedelta(seconds=1),\n",
    "                      \"MINUTE\" : timedelta(minutes=1),\n",
    "                    #   \"HOUR\" : timedelta(hours=1),\n",
    "                    }\n",
    "\n",
    "\n",
    "# check if file does't already exist\n",
    "\n",
    "pymeos_initialize()\n",
    "db = Database_connector2()\n",
    "\n",
    "x_min = float(args[3])\n",
    "y_min = float(args[4])\n",
    "x_max = float(args[5])\n",
    "y_max = float(args[6])\n",
    "\n",
    "start_date = args[7]\n",
    "start_date = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "total_frames = int(args[8])\n",
    "GRANULARITY = Time_granularities[args[9]]\n",
    "\n",
    "timestamps = []\n",
    "for i in range(total_frames): \n",
    "    timestamps.append(start_date + i*GRANULARITY)\n",
    "\n",
    "\n",
    "\n",
    "p_start = timestamps[begin_frame]\n",
    "p_end = timestamps[end_frame]\n",
    "# print(p_start, p_end, x_min, y_min, x_max, y_max)\n",
    "now_db = time.time()\n",
    "rows = db.get_subset_of_tpoints(p_start, p_end, x_min, y_min, x_max, y_max)    \n",
    "\n",
    "print(f\"Time to fetch tpoints : {time.time() - now_db} s\")    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 0 created in 15.015557765960693 seconds, 450.4667329788208 frames for 30 fps animation.\n"
     ]
    }
   ],
   "source": [
    "empty_point_wkt = Point()  # \"POINT EMPTY\"\n",
    "matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "\n",
    "time_ranges = timestamps\n",
    "now = time.time()\n",
    "\n",
    "# try:\n",
    "for i in range(len(rows)):\n",
    "    if rows[i][0] is not None:\n",
    "        try:\n",
    "            traj_resampled = rows[i][0]\n",
    "\n",
    "            start_index = time_ranges.index( traj_resampled.start_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) - begin_frame\n",
    "            end_index = time_ranges.index( traj_resampled.end_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) - begin_frame\n",
    "            matrix[i, start_index:end_index+1] = np.array(traj_resampled.values())\n",
    "    \n",
    "        except:\n",
    "            print(i)\n",
    "            # continue\n",
    "\n",
    "\n",
    "# db.close()\n",
    "# pymeos_finalize()\n",
    "total_time = time.time() - now\n",
    "frames_for_30_fps= 30 * total_time\n",
    "print(f\"Matrix {begin_frame} created in {total_time} seconds, {frames_for_30_fps} frames for 30 fps animation.\")\n",
    "# logs += f\"time to create and fill the matrix {begin_frame}: {total_time} seconds\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2794080"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(matrix != 'POINT EMPTY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opr(rows):\n",
    "    empty_point_wkt = Point()  # \"POINT EMPTY\"\n",
    "    matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "\n",
    "    time_ranges = timestamps\n",
    "    now = time.time()\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        if rows[i][0] is not None:\n",
    "            try:\n",
    "                traj_resampled = rows[i][0]\n",
    "                # num_instants = traj_resampled.num_instants()\n",
    "                # if num_instants == 1:\n",
    "                #     # print(f\"{i} has one instant\")\n",
    "                #     single_timestamp = traj_resampled.timestamps()[0].replace(tzinfo=None).replace(second=0, microsecond=0)\n",
    "                #     index = time_ranges.index(single_timestamp) - begin_frame\n",
    "                #     matrix[i][index] = traj.values()[0].wkt\n",
    "                \n",
    "                # elif num_instants >= 2:\n",
    "                    # traj_resampled = traj.temporal_sample(start=time_ranges[0],duration= GRANULARITY)\n",
    "                    \n",
    "                start_index = time_ranges.index( traj_resampled.start_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) - begin_frame\n",
    "                end_index = time_ranges.index( traj_resampled.end_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) - begin_frame\n",
    "                vals = traj_resampled.values()\n",
    "                trajectory_array = np.array(vals)\n",
    "                matrix[i, start_index:end_index+1] = trajectory_array\n",
    "        \n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "    # db.close()\n",
    "    # pymeos_finalize()\n",
    "    total_time = time.time() - now\n",
    "    frames_for_30_fps= 30 * total_time\n",
    "    print(f\"Matrix {begin_frame} created in {total_time} seconds, {frames_for_30_fps} frames for 30 fps animation.\")\n",
    "    # logs += f\"time to create and fill the matrix {begin_frame}: {total_time} seconds\\n\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 0 created in 25.74210810661316 seconds, 772.2632431983948 frames for 30 fps animation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 25.1043 s\n",
      "File: /tmp/ipykernel_5042/310096134.py\n",
      "Function: opr at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def opr(rows):\n",
      "     2         1      54306.0  54306.0      0.0      empty_point_wkt = Point()  # \"POINT EMPTY\"\n",
      "     3         1    6041035.0    6e+06      0.0      matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
      "     4                                           \n",
      "     5         1        392.0    392.0      0.0      time_ranges = timestamps\n",
      "     6         1        716.0    716.0      0.0      now = time.time()\n",
      "     7                                           \n",
      "     8      5822    1132901.0    194.6      0.0      for i in range(len(rows)):\n",
      "     9      5821    1072371.0    184.2      0.0          if rows[i][0] is not None:\n",
      "    10      4174     365683.0     87.6      0.0              try:\n",
      "    11      4174     670280.0    160.6      0.0                  traj_resampled = rows[i][0]\n",
      "    12                                                           # num_instants = traj_resampled.num_instants()\n",
      "    13                                                           # if num_instants == 1:\n",
      "    14                                                           #     # print(f\"{i} has one instant\")\n",
      "    15                                                           #     single_timestamp = traj_resampled.timestamps()[0].replace(tzinfo=None).replace(second=0, microsecond=0)\n",
      "    16                                                           #     index = time_ranges.index(single_timestamp) - begin_frame\n",
      "    17                                                           #     matrix[i][index] = traj.values()[0].wkt\n",
      "    18                                                           \n",
      "    19                                                           # elif num_instants >= 2:\n",
      "    20                                                               # traj_resampled = traj.temporal_sample(start=time_ranges[0],duration= GRANULARITY)\n",
      "    21                                                               \n",
      "    22      4174  575559857.0 137891.7      2.3                  start_index = time_ranges.index( traj_resampled.start_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) - begin_frame\n",
      "    23      4174  501858229.0 120234.4      2.0                  end_index = time_ranges.index( traj_resampled.end_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) - begin_frame\n",
      "    24      4174        2e+10    6e+06     92.1                  vals = traj_resampled.values()\n",
      "    25      4174  891890603.0 213677.7      3.6                  trajectory_array = np.array(vals)\n",
      "    26      4174   10348811.0   2479.4      0.0                  matrix[i, start_index:end_index+1] = trajectory_array\n",
      "    27                                                   \n",
      "    28                                                       except:\n",
      "    29                                                           continue\n",
      "    30                                           \n",
      "    31                                           \n",
      "    32                                               # db.close()\n",
      "    33                                               # pymeos_finalize()\n",
      "    34         1       1385.0   1385.0      0.0      total_time = time.time() - now\n",
      "    35         1        410.0    410.0      0.0      frames_for_30_fps= 30 * total_time\n",
      "    36         1      83384.0  83384.0      0.0      print(f\"Matrix {begin_frame} created in {total_time} seconds, {frames_for_30_fps} frames for 30 fps animation.\")\n",
      "    37                                               # logs += f\"time to create and fill the matrix {begin_frame}: {total_time} seconds\\n\""
     ]
    }
   ],
   "source": [
    "%lprun -f opr opr(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time to fill the matrix : 19.8060622215271 s\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    if rows[i][0] is not None:\n",
    "        try:\n",
    "            traj_resampled = rows[i][0]\n",
    "\n",
    "            start_index = time_ranges.index( traj_resampled.start_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) - begin_frame\n",
    "            end_index = time_ranges.index( traj_resampled.end_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) - begin_frame\n",
    "            vals = traj_resampled.values()\n",
    "            trajectory_array = np.array([point.wkt for point in vals])\n",
    "            matrix[i, start_index:end_index+1] = trajectory_array\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "print(f\" Time to fill the matrix : {time.time() - now} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to fill the matrix : 23.57325553894043 s\n"
     ]
    }
   ],
   "source": [
    "x1 = TGeomPointInst(point=(0, 0), timestamp=timestamps[0])\n",
    "x2 = TGeomPointInst(point=(1, 1), timestamp=timestamps[TIME_DELTA_SIZE-1])\n",
    "traj = TGeomPointSeq.from_instants([x1, x2], upper_inc=True)\n",
    "traj_resampled = traj.temporal_sample(start=timestamps[0],duration= GRANULARITY)\n",
    "empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "trajectory_array = np.array([point.wkt for point in traj_resampled.values()])\n",
    "trajectory_array\n",
    "\n",
    "now = time.time()\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    if 1 == 1 :\n",
    "        try:\n",
    "            start_index = timestamps.index( traj_resampled.start_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) \n",
    "            end_index = timestamps.index( traj_resampled.end_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) \n",
    "\n",
    "            trajectory_array = np.array([point.wkt for point in traj_resampled.values()])\n",
    "            matrix[i, start_index:end_index+1] = trajectory_array\n",
    "        except:\n",
    "            continue\n",
    "print(f\"Time to fill the matrix : {time.time() - now} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 0 created in 34.37529969215393 seconds, 1031.258990764618 frames for 30 fps animation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 33.4186 s\n",
      "File: /tmp/ipykernel_5042/2884772419.py\n",
      "Function: opr at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def opr(rows):\n",
      "     2         1      68870.0  68870.0      0.0      empty_point_wkt = Point()  # \"POINT EMPTY\"\n",
      "     3         1    6289944.0    6e+06      0.0      matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
      "     4                                           \n",
      "     5         1        410.0    410.0      0.0      time_ranges = timestamps\n",
      "     6         1        889.0    889.0      0.0      now = time.time()\n",
      "     7                                           \n",
      "     8      5822    1172389.0    201.4      0.0      for i in range(len(rows)):\n",
      "     9      5821    1257898.0    216.1      0.0          if rows[i][0] is not None:\n",
      "    10      4174     417364.0    100.0      0.0              try:\n",
      "    11      4174     507546.0    121.6      0.0                  traj_resampled = rows[i][0]\n",
      "    12                                                           # num_instants = traj_resampled.num_instants()\n",
      "    13                                                           # if num_instants == 1:\n",
      "    14                                                           #     # print(f\"{i} has one instant\")\n",
      "    15                                                           #     single_timestamp = traj_resampled.timestamps()[0].replace(tzinfo=None).replace(second=0, microsecond=0)\n",
      "    16                                                           #     index = time_ranges.index(single_timestamp) - begin_frame\n",
      "    17                                                           #     matrix[i][index] = traj.values()[0].wkt\n",
      "    18                                                           \n",
      "    19                                                           # elif num_instants >= 2:\n",
      "    20                                                               # traj_resampled = traj.temporal_sample(start=time_ranges[0],duration= GRANULARITY)\n",
      "    21                                                               \n",
      "    22      4174  588214633.0 140923.5      1.8                  start_index = time_ranges.index( traj_resampled.start_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) - begin_frame\n",
      "    23      4174  498251154.0 119370.2      1.5                  end_index = time_ranges.index( traj_resampled.end_timestamp().replace(tzinfo=None).replace(second=0, microsecond=0) ) - begin_frame\n",
      "    24      4174        2e+10    5e+06     66.8                  vals = traj_resampled.values()\n",
      "    25   1651784 9934704955.0   6014.5     29.7                  trajectory_array = np.array([point.wkt for point in vals])\n",
      "    26      4174   63227725.0  15148.0      0.2                  matrix[i, start_index:end_index+1] = trajectory_array\n",
      "    27                                                   \n",
      "    28                                                       except:\n",
      "    29                                                           continue\n",
      "    30                                           \n",
      "    31                                           \n",
      "    32                                               # db.close()\n",
      "    33                                               # pymeos_finalize()\n",
      "    34         1       1967.0   1967.0      0.0      total_time = time.time() - now\n",
      "    35         1        409.0    409.0      0.0      frames_for_30_fps= 30 * total_time\n",
      "    36         1      99131.0  99131.0      0.0      print(f\"Matrix {begin_frame} created in {total_time} seconds, {frames_for_30_fps} frames for 30 fps animation.\")\n",
      "    37                                               # logs += f\"time to create and fill the matrix {begin_frame}: {total_time} seconds\\n\""
     ]
    }
   ],
   "source": [
    "%lprun -f opr opr(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting line_profiler\n",
      "  Downloading line_profiler-4.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Downloading line_profiler-4.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (720 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.6/720.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: line_profiler\n",
      "Successfully installed line_profiler-4.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "865790"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(matrix != 'POINT EMPTY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Resampling AND the operations of finding the indexes in database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '59',\n",
       " '1',\n",
       " '-180',\n",
       " '-90',\n",
       " '180',\n",
       " '90',\n",
       " '2023-06-01 00:00:00',\n",
       " '1440',\n",
       " 'SECOND',\n",
       " '/home/ali/matrices/60_1',\n",
       " 'mobilitydb',\n",
       " 'processed_data',\n",
       " 'MMSI',\n",
       " 'traj']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments = ['0', '59', '1', '-180', '-90', '180', '90', '2023-06-01 00:00:00', '1440', 'SECOND', '/home/ali/matrices/60_1', 'mobilitydb', 'processed_data', 'MMSI', 'traj']\n",
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to fetch tpoints : 2.164764165878296 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from pymeos.db.psycopg import MobilityDB\n",
    "\n",
    "from pymeos import *\n",
    "import os\n",
    "import sys\n",
    "from datetime import timedelta, datetime\n",
    "from pymeos import *\n",
    "import time\n",
    "\n",
    "logs = \"\"\n",
    "now = time.time()\n",
    "\n",
    "FPS_DEQUEUE_SIZE = 5 # Length of the dequeue to calculate the average FPS\n",
    "TIME_DELTA_DEQUEUE_SIZE =  10 # Length of the dequeue to keep the keys to keep in the buffer\n",
    "\n",
    "\n",
    "args = arguments\n",
    "logs += f\"Args: {args}\\n\"\n",
    "begin_frame = int(args[0])\n",
    "end_frame = int(args[1])\n",
    "TIME_DELTA_SIZE = end_frame - begin_frame + 1\n",
    "PERCENTAGE_OF_OBJECTS = float(args[2])\n",
    "\n",
    "\n",
    "SRID = 4326\n",
    "\n",
    "\n",
    "DATABASE_NAME = args[11]\n",
    "TPOINT_TABLE_NAME = args[12]\n",
    "TPOINT_ID_COLUMN_NAME = args[13]\n",
    "TPOINT_COLUMN_NAME = args[14]\n",
    "\n",
    "\n",
    "\n",
    "class Database_connector3:\n",
    "    \"\"\"\n",
    "    Singleton class used to connect to the MobilityDB database.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        try: \n",
    "            connection_params = {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 5432,\n",
    "            \"dbname\": DATABASE_NAME,\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"postgres\"\n",
    "            }\n",
    "            self.table_name = TPOINT_TABLE_NAME\n",
    "            self.id_column_name = TPOINT_ID_COLUMN_NAME\n",
    "            self.tpoint_column_name = TPOINT_COLUMN_NAME               \n",
    "            self.connection = MobilityDB.connect(**connection_params)\n",
    "\n",
    "            self.cursor = self.connection.cursor()\n",
    "\n",
    "            self.cursor.execute(f\"SELECT {self.id_column_name} FROM public.{self.table_name};\")\n",
    "            self.ids_list = self.cursor.fetchall()\n",
    "            self.ids_list = self.ids_list[:int(len(self.ids_list)*PERCENTAGE_OF_OBJECTS)]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "  \n",
    "    def get_subset_of_tpoints(self, pstart, pend, xmin, ymin, xmax, ymax, begin_frame):\n",
    "        \"\"\"\n",
    "        For each object in the ids_list :\n",
    "            Fetch the subset of the associated Tpoints between the start and end timestamps\n",
    "            contained in the STBOX defined by the xmin, ymin, xmax, ymax.\n",
    "        \"\"\"\n",
    "        try:\n",
    "           \n",
    "            ids_list = [ f\"'{id[0]}'\"  for id in self.ids_list]\n",
    "            ids_str = ', '.join(map(str, ids_list))\n",
    "          \n",
    "            query = f\"\"\"\n",
    "                    WITH trajectories as (\n",
    "                    SELECT \n",
    "                        atStbox(\n",
    "                            a.{self.tpoint_column_name}::tgeompoint,\n",
    "                            stbox(\n",
    "                                ST_MakeEnvelope(\n",
    "                                    {xmin}, {ymin}, -- xmin, ymin\n",
    "                                    {xmax}, {ymax}, -- xmax, ymax\n",
    "                                    4326 -- SRID\n",
    "                                ),\n",
    "                                tstzspan('[{pstart}, {pend}]')\n",
    "                            )\n",
    "                        ) as trajectory\n",
    "                    FROM public.{self.table_name} as a \n",
    "                    WHERE a.{self.id_column_name} in ({ids_str})),\n",
    "\n",
    "                    resampled as (\n",
    "\n",
    "                    SELECT tsample(traj.trajectory, INTERVAL '1 minute', TIMESTAMP '2023-06-01 00:00:00')  AS resampled_trajectory\n",
    "                        FROM \n",
    "                            trajectories as traj)\n",
    "\t\t\t\t\n",
    "                    SELECT\n",
    "                            ( EXTRACT(EPOCH FROM (startTimestamp(rs.resampled_trajectory) - '2023-06-01 00:00:00'::timestamp))::integer / 60 ) - {begin_frame} AS start_index ,\n",
    "                            ( EXTRACT(EPOCH FROM (endTimestamp(rs.resampled_trajectory) - '2023-06-01 00:00:00'::timestamp))::integer / 60 ) - {begin_frame} AS end_index,\n",
    "                            rs.resampled_trajectory\n",
    "                    FROM resampled as rs ;\n",
    " \n",
    "                    \"\"\"\n",
    "            self.cursor.execute(query)\n",
    "            # print(query)\n",
    "            rows = self.cursor.fetchall()\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            pass\n",
    "\n",
    "\n",
    "    def get_min_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the min timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            self.cursor.execute(f\"SELECT MIN(startTimestamp({self.tpoint_column_name})) AS earliest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    def get_max_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the max timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.cursor.execute(f\"SELECT MAX(endTimestamp({self.tpoint_column_name})) AS latest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close the connection to the MobilityDB database.\n",
    "        \"\"\"\n",
    "        self.cursor.close()\n",
    "        self.connection.close()\n",
    "\n",
    "\n",
    "MATRIX_DIRECTORY_PATH = \"/home/ali/matrices\"\n",
    "file_name = f\"/home/ali/matrices/matrix_{begin_frame}.npy\"\n",
    "\n",
    "\n",
    "  \n",
    "Time_granularities = {\n",
    "                    # \"MILLISECOND\" : timedelta(milliseconds=1),\n",
    "                      \"SECOND\" : timedelta(seconds=1),\n",
    "                      \"MINUTE\" : timedelta(minutes=1),\n",
    "                    #   \"HOUR\" : timedelta(hours=1),\n",
    "                    }\n",
    "\n",
    "\n",
    "# check if file does't already exist\n",
    "\n",
    "pymeos_initialize()\n",
    "db = Database_connector3()\n",
    "\n",
    "x_min = float(args[3])\n",
    "y_min = float(args[4])\n",
    "x_max = float(args[5])\n",
    "y_max = float(args[6])\n",
    "\n",
    "start_date = args[7]\n",
    "start_date = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "total_frames = int(args[8])\n",
    "GRANULARITY = Time_granularities[args[9]]\n",
    "\n",
    "timestamps = []\n",
    "for i in range(total_frames): \n",
    "    timestamps.append(start_date + i*GRANULARITY)\n",
    "\n",
    "\n",
    "\n",
    "p_start = timestamps[begin_frame]\n",
    "p_end = timestamps[end_frame]\n",
    "# print(p_start, p_end, x_min, y_min, x_max, y_max)\n",
    "now_db = time.time()\n",
    "rows = db.get_subset_of_tpoints(p_start, p_end, x_min, y_min, x_max, y_max, begin_frame)    \n",
    "\n",
    "print(f\"Time to fetch tpoints : {time.time() - now_db} s\")    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix 0 created in 0.14333271980285645 seconds, 4.299981594085693 frames for 30 fps animation.\n"
     ]
    }
   ],
   "source": [
    "empty_point_wkt = Point()  # \"POINT EMPTY\"\n",
    "matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "\n",
    "time_ranges = timestamps\n",
    "now = time.time()\n",
    "\n",
    "# try:\n",
    "for i in range(len(rows)):\n",
    "    if rows[i][2] is not None:\n",
    "        try:\n",
    "            traj_resampled = rows[i][2]\n",
    "\n",
    "            start_index = rows[i][0] \n",
    "            end_index = rows[i][1]\n",
    "            matrix[i, start_index:end_index+1] = np.array(traj_resampled.values())\n",
    "    \n",
    "        except:\n",
    "            print(i)\n",
    "            # continue\n",
    "\n",
    "\n",
    "# db.close()\n",
    "# pymeos_finalize()\n",
    "total_time = time.time() - now\n",
    "frames_for_30_fps= 30 * total_time\n",
    "print(f\"Matrix {begin_frame} created in {total_time} seconds, {frames_for_30_fps} frames for 30 fps animation.\")\n",
    "# logs += f\"time to create and fill the matrix {begin_frame}: {total_time} seconds\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2794080"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(matrix != 'POINT EMPTY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring nditer vs for loop for feature generation\n",
    "\n",
    "Python For loops are expensives, numpy offers the nditer tool to iterate over its arrays, but on small operations this might not be worth the hassle to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962 µs ± 39.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "# create a numpy array of size len(ids_list) with empty_point_wkt\n",
    "starting_points = np.full((1, 5821), empty_point_wkt, dtype=object)\n",
    "\n",
    "qgis_fields_list = []\n",
    "\n",
    "for wkt in np.nditer(starting_points, flags=['refs_ok']):\n",
    "    feat = [\"vlayer_fields\"]\n",
    "    feat.append(\"datetime_obj\")  # Set its attributes\n",
    "    # Create geometry from WKT string\n",
    "    feat.append(wkt.item())\n",
    "    qgis_fields_list.append(feat)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378 µs ± 2.94 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "\n",
    "qgis_fields_list = []\n",
    "\n",
    "for i in range(5821):\n",
    "    feat = [\"vlayer_fields\"]\n",
    "    feat.append(\"datetime_obj\")  # Set its attributes\n",
    "    # Create geometry from WKT string\n",
    "    feat.append(empty_point_wkt)\n",
    "    qgis_fields_list.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annex code to build the threading solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Include the PYQGIS imports for the plugin\n",
    "from pymeos.db.psycopg import MobilityDB\n",
    "from pymeos import *\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import deque\n",
    "from pympler import asizeof\n",
    "import gc\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import math\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "\n",
    "pymeos_initialize()\n",
    "DATABASE_NAME = \"mobilitydb\"\n",
    "TPOINT_TABLE_NAME = \"PyMEOS_demo\"\n",
    "TPOINT_ID_COLUMN_NAME = \"MMSI\"\n",
    "TPOINT_COLUMN_NAME = \"trajectory\"\n",
    "\n",
    "SRID = 4326\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_granularities = {\n",
    "                # \"MILLISECOND\" : timedelta(milliseconds=1),\n",
    "                    \"SECOND\" : timedelta(seconds=1),\n",
    "                    \"MINUTE\" : timedelta(minutes=1),\n",
    "                #   \"HOUR\" : timedelta(hours=1),\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database_connector:\n",
    "    \"\"\"\n",
    "    Singleton class used to connect to the MobilityDB database.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        try: \n",
    "            connection_params = {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 5432,\n",
    "            \"dbname\": DATABASE_NAME,\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"postgres\"\n",
    "            }\n",
    "            self.table_name = TPOINT_TABLE_NAME\n",
    "            self.id_column_name = TPOINT_ID_COLUMN_NAME\n",
    "            self.tpoint_column_name = TPOINT_COLUMN_NAME               \n",
    "            self.connection = MobilityDB.connect(**connection_params)\n",
    "\n",
    "            self.cursor = self.connection.cursor()\n",
    "\n",
    "            self.cursor.execute(f\"SELECT {self.id_column_name} FROM public.{self.table_name};\")\n",
    "            self.ids_list = self.cursor.fetchall()\n",
    "            self.ids_list = self.ids_list[:int(len(self.ids_list)*PERCENTAGE_OF_OBJECTS)]\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    def get_min_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the min timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            self.cursor.execute(f\"SELECT MIN(startTimestamp({self.tpoint_column_name})) AS earliest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    def get_max_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the max timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.cursor.execute(f\"SELECT MAX(endTimestamp({self.tpoint_column_name})) AS latest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    def get_subset_of_tpoints(self, pstart, pend, xmin, ymin, xmax, ymax, time_granularity, start_date):\n",
    "        \"\"\"\n",
    "        For each object in the ids_list :\n",
    "            Fetch the subset of the associated Tpoints between the start and end timestamps\n",
    "            contained in the STBOX defined by the xmin, ymin, xmax, ymax.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            ids_list = [ f\"'{id[0]}'\"  for id in self.ids_list]\n",
    "            ids_str = ', '.join(map(str, ids_list))\n",
    "\n",
    "            if time_granularity == \"SECOND\":\n",
    "                time_value = 1\n",
    "            elif time_granularity == \"MINUTE\":\n",
    "                time_value = 60\n",
    "            \n",
    "            # return [self.tpoint_column_name, self.id_column_name, ids_str, xmin, ymin, xmax, ymax, pstart, pend, time_granularity, start_date, time_value]\n",
    "            query = f\"\"\"WITH trajectories as (\n",
    "                    SELECT \n",
    "                        atStbox(\n",
    "                            a.{self.tpoint_column_name}::tgeompoint,\n",
    "                            stbox(\n",
    "                                ST_MakeEnvelope(\n",
    "                                    {xmin}, {ymin}, -- xmin, ymin\n",
    "                                    {xmax}, {ymax}, -- xmax, ymax\n",
    "                                    4326 -- SRID\n",
    "                                ),\n",
    "                                tstzspan('[{pstart}, {pend}]')\n",
    "                            )\n",
    "                        ) as trajectory\n",
    "                    FROM public.{self.table_name} as a \n",
    "                    WHERE a.{self.id_column_name} in ({ids_str})),\n",
    "\n",
    "                    resampled as (\n",
    "\n",
    "                    SELECT tsample(traj.trajectory, INTERVAL '1 {time_granularity}', TIMESTAMP '{start_date}')  AS resampled_trajectory\n",
    "                        FROM \n",
    "                            trajectories as traj)\n",
    "\t\t\t\t\n",
    "                    SELECT\n",
    "                            EXTRACT(EPOCH FROM (startTimestamp(rs.resampled_trajectory) - '{start_date}'::timestamp))::integer / {time_value} AS start_index ,\n",
    "                            EXTRACT(EPOCH FROM (endTimestamp(rs.resampled_trajectory) - '{start_date}'::timestamp))::integer / {time_value} AS end_index,\n",
    "                            rs.resampled_trajectory\n",
    "                    FROM resampled as rs ;\"\"\"\n",
    "        \n",
    "            self.cursor.execute(query)\n",
    "       \n",
    "            rows = self.cursor.fetchall()\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            print(query)\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close the connection to the MobilityDB database.\n",
    "        \"\"\"\n",
    "        self.cursor.close()\n",
    "        self.connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Database_connector()\n",
    "GRANULARITY = Time_granularities[\"MINUTE\"]\n",
    "start_date = db.get_min_timestamp()\n",
    "end_date = db.get_max_timestamp()\n",
    "total_frames = math.ceil( (end_date - start_date) // GRANULARITY )\n",
    "\n",
    "timestamps = [start_date + i * GRANULARITY for i in range(total_frames)]\n",
    "timestamps = [dt.replace(tzinfo=None) for dt in timestamps]\n",
    "timestamps_strings = [dt.strftime('%Y-%m-%d %H:%M:%S') for dt in timestamps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1439"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Threading\n",
    "\n",
    "In order to get rid of Subprocess without having the dips in framerate when changing the time delta, we are experimenting with the threading library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (6000, 1440)\n",
      "hello\n",
      "Retrieved matrix shape: (6000, 1440)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import threading\n",
    "from shapely.geometry import Point\n",
    "from queue import Queue\n",
    "\n",
    "def create_matrix(result_queue, arg2):\n",
    "    empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    matrix = np.full((6000, 1440), empty_point_wkt)  # Creates a matrix filled with 'POINT EMPTY'\n",
    "    print(\"Matrix shape:\", matrix.shape)\n",
    "    print(arg2)\n",
    "    result_queue.put(matrix)  # Put the result in the queue\n",
    "\n",
    "# Create a queue to hold the result\n",
    "result_queue = Queue()\n",
    "\n",
    "# Creating and starting a new thread to generate the matrix\n",
    "thread = threading.Thread(target=create_matrix, args=(result_queue,\"hello\"))\n",
    "thread.start()\n",
    "thread.join()  # Wait for the thread to complete\n",
    "\n",
    "# Retrieve the result from the queue\n",
    "result_matrix = result_queue.get()\n",
    "print(\"Retrieved matrix shape:\", result_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 1440)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [0, 59, 60, 0.1, -180, -90, 180, 90, timestamps, 'SECOND',db]\n",
    "len(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok2\n",
      "ok3\n",
      "Retrieved matrix shape: [['POINT EMPTY' 'POINT EMPTY' 'POINT EMPTY' ... 'POINT EMPTY'\n",
      "  'POINT EMPTY' 'POINT EMPTY']\n",
      " ['POINT (8.42333 55.4718)' 'POINT (8.42333 55.4718)'\n",
      "  'POINT (8.42333 55.4718)' ... 'POINT (8.42335 55.4718)'\n",
      "  'POINT (8.42335 55.4718)' 'POINT (8.42335 55.4718)']\n",
      " ['POINT EMPTY' 'POINT EMPTY' 'POINT EMPTY' ... 'POINT EMPTY'\n",
      "  'POINT EMPTY' 'POINT EMPTY']\n",
      " ...\n",
      " ['POINT EMPTY' 'POINT EMPTY' 'POINT EMPTY' ... 'POINT EMPTY'\n",
      "  'POINT EMPTY' 'POINT EMPTY']\n",
      " ['POINT EMPTY' 'POINT EMPTY' 'POINT EMPTY' ... 'POINT EMPTY'\n",
      "  'POINT EMPTY' 'POINT EMPTY']\n",
      " ['POINT EMPTY' 'POINT EMPTY' 'POINT EMPTY' ... 'POINT EMPTY'\n",
      "  'POINT EMPTY' 'POINT EMPTY']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import threading\n",
    "from shapely.geometry import Point\n",
    "from queue import Queue\n",
    "\n",
    "def create_matrix(result_queue, begin_frame, end_frame, TIME_DELTA_SIZE, PERCENTAGE_OF_OBJECTS, x_min, y_min, x_max, y_max, timestamps, total_frames, GRANULARITY, db):\n",
    "    # a  =f\"all parameters : {begin_frame, end_frame, TIME_DELTA_SIZE, PERCENTAGE_OF_OBJECTS, x_min, y_min, x_max, y_max, len(timestamps), total_frames, GRANULARITY, db}\"\n",
    "    # result_queue.put(a)  \n",
    "    p_start = timestamps[begin_frame]\n",
    "    p_end = timestamps[end_frame]\n",
    "    # print(p_start, p_end, x_min, y_min, x_max, y_max)\n",
    "    # now_db = time.time()\n",
    "    rows = db.get_subset_of_tpoints(p_start, p_end, x_min, y_min, x_max, y_max, GRANULARITY, start_date)    \n",
    "    # print(f\"Time to fetch subset of tpoints: {time.time() - now_db} seconds\\n\")\n",
    "            \n",
    "    empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "    \n",
    "\n",
    "    # now = time.time()\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        if rows[i][2] is not None:\n",
    "            try:\n",
    "                traj_resampled = rows[i][2]\n",
    "\n",
    "                start_index = rows[i][0] - begin_frame\n",
    "                end_index = rows[i][1] - begin_frame\n",
    "                values = np.array([point.wkt for point in traj_resampled.values()])\n",
    "                matrix[i, start_index:end_index+1] = values\n",
    "        \n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    result_queue.put(matrix)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    # matrix = np.full((6000, 1440), empty_point_wkt)  # Creates a matrix filled with 'POINT EMPTY'\n",
    "    # print(\"Matrix shape:\", matrix.shape)\n",
    "    # print(arg2)\n",
    "    # result_queue.put(matrix)  # Put the result in the queue\n",
    "\n",
    "# Create a queue to hold the result\n",
    "print(\"ok\")\n",
    "result_queue = Queue()\n",
    "# Creating and starting a new thread to generate the matrix\n",
    "thread = threading.Thread(target=create_matrix, args=(result_queue, 0, 59, 60, 0.1, -180, -90, 180, 90, timestamps,len(timestamps), 'SECOND',db))\n",
    "thread.start()\n",
    "print(\"ok2\")\n",
    "thread.join()  # Wait for the thread to complete\n",
    "print(\"ok3\")\n",
    "# Retrieve the result from the queue\n",
    "result_matrix = result_queue.get()\n",
    "print(\"Retrieved matrix shape:\", result_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import threading\n",
    "from shapely.geometry import Point\n",
    "from queue import Queue\n",
    "\n",
    "def create_matrix(result_queue, begin_frame, end_frame, TIME_DELTA_SIZE, PERCENTAGE_OF_OBJECTS, x_min, y_min, x_max, y_max, timestamps, total_frames, GRANULARITY, ids_list):\n",
    "    # a  =f\"all parameters : {begin_frame, end_frame, TIME_DELTA_SIZE, PERCENTAGE_OF_OBJECTS, x_min, y_min, x_max, y_max, len(timestamps), total_frames, GRANULARITY, db}\"\n",
    "    # result_queue.put(a)  \n",
    "    p_start = timestamps[begin_frame]\n",
    "    p_end = timestamps[end_frame]\n",
    "    start_date = timestamps[0]\n",
    "    connection_params = {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 5432,\n",
    "            \"dbname\": \"mobilitydb\",\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"postgres\"\n",
    "            }\n",
    "    table_name = \"pymeos_demo\"\n",
    "    id_column_name = \"mmsi\"\n",
    "    tpoint_column_name = \"trajectory\"               \n",
    "    connection = MobilityDB.connect(**connection_params)\n",
    "    \n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    ids_list = [ f\"'{id[0]}'\"  for id in ids_list]\n",
    "    ids_str = ', '.join(map(str, ids_list))\n",
    "\n",
    "    if GRANULARITY == \"SECOND\":\n",
    "        time_value = 1\n",
    "    elif GRANULARITY == \"MINUTE\":\n",
    "        time_value = 60\n",
    "            \n",
    "    # return [self.tpoint_column_name, self.id_column_name, ids_str, xmin, ymin, xmax, ymax, pstart, pend, time_granularity, start_date, time_value]\n",
    "    query = f\"\"\"WITH trajectories as (\n",
    "            SELECT \n",
    "                atStbox(\n",
    "                    a.{tpoint_column_name}::tgeompoint,\n",
    "                    stbox(\n",
    "                        ST_MakeEnvelope(\n",
    "                            {x_min}, {y_min}, -- xmin, ymin\n",
    "                            {x_max}, {y_max}, -- xmax, ymax\n",
    "                            4326 -- SRID\n",
    "                        ),\n",
    "                        tstzspan('[{p_start}, {p_end}]')\n",
    "                    )\n",
    "                ) as trajectory\n",
    "            FROM public.{table_name} as a \n",
    "            WHERE a.{id_column_name} in ({ids_str})),\n",
    "\n",
    "            resampled as (\n",
    "\n",
    "            SELECT tsample(traj.trajectory, INTERVAL '1 {GRANULARITY}', TIMESTAMP '{start_date}')  AS resampled_trajectory\n",
    "                FROM \n",
    "                    trajectories as traj)\n",
    "        \n",
    "            SELECT\n",
    "                    EXTRACT(EPOCH FROM (startTimestamp(rs.resampled_trajectory) - '{start_date}'::timestamp))::integer / {time_value} AS start_index ,\n",
    "                    EXTRACT(EPOCH FROM (endTimestamp(rs.resampled_trajectory) - '{start_date}'::timestamp))::integer / {time_value} AS end_index,\n",
    "                    rs.resampled_trajectory\n",
    "            FROM resampled as rs ;\"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "\n",
    "    rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "       \n",
    "    empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "    \n",
    "\n",
    "    # now = time.time()\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        if rows[i][2] is not None:\n",
    "            try:\n",
    "                traj_resampled = rows[i][2]\n",
    "\n",
    "                start_index = rows[i][0] - begin_frame\n",
    "                end_index = rows[i][1] - begin_frame\n",
    "                values = np.array([point.wkt for point in traj_resampled.values()])\n",
    "                matrix[i, start_index:end_index+1] = values\n",
    "        \n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    result_queue.put(matrix)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    # matrix = np.full((6000, 1440), empty_point_wkt)  # Creates a matrix filled with 'POINT EMPTY'\n",
    "    # print(\"Matrix shape:\", matrix.shape)\n",
    "    # print(arg2)\n",
    "    # result_queue.put(matrix)  # Put the result in the queue\n",
    "\n",
    "# Create a queue to hold the result\n",
    "print(\"ok\")\n",
    "result_queue = Queue()\n",
    "# Creating and starting a new thread to generate the matrix\n",
    "thread = threading.Thread(target=create_matrix, args=(result_queue, 60, 119, 60, 0.1, -180, -90, 180, 90, timestamps,len(timestamps), 'MINUTE',db.ids_list))\n",
    "thread.start()\n",
    "print(\"ok2\")\n",
    "thread.join()  # Wait for the thread to complete\n",
    "print(\"ok3\")\n",
    "# Retrieve the result from the queue\n",
    "result_matrix = result_queue.get()\n",
    "print(\"Retrieved matrix shape:\", result_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "TypeError: create_matrix() takes 2 positional arguments but 13 were given\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m process\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# while(True):\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mresult_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(a))\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:430\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 430\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:395\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import multiprocessing\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def create_matrix(result_queue, hello):\n",
    "    print(hello)\n",
    "    empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    # Creates a matrix filled with 'POINT EMPTY'\n",
    "    matrix = np.full((6000, 1440), empty_point_wkt, dtype=object)\n",
    "    # print(\"Matrix shape:\", matrix.shape)\n",
    "    result_queue.put(matrix)  # Put the result in the queue\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Using Manager's queue\n",
    "    # manager = multiprocessing.Manager()\n",
    "    result_queue = multiprocessing.Queue()\n",
    "\n",
    "    # Creating and starting a new process to generate the matrix\n",
    "    process = multiprocessing.Process(target=create_matrix, args=(result_queue,\"hello\"))\n",
    "    process.start()\n",
    "    # while(True):\n",
    "    a = result_queue.get()\n",
    "    print(a)\n",
    "    print(type(a))\n",
    "    print(len(a))\n",
    "    print(a.shape)\n",
    "        \n",
    "    process.join()  # Wait for the process to complete\n",
    "    \n",
    "    print(\"Process ended\")\n",
    "    # # Retrieve the result from the queue\n",
    "    # result_matrix = result_queue.get()\n",
    "    # print(\"Retrieved matrix shape:\", result_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok2\n",
      "ok3 rows\n",
      "ok4 matrix\n",
      "[['POINT EMPTY' 'POINT EMPTY' 'POINT EMPTY' ... 'POINT (12.6058 55.6843)'\n",
      "  'POINT (12.6058 55.6843)' 'POINT (12.6058 55.6843)']\n",
      " ['POINT (8.42334 55.4718)' 'POINT (8.42334 55.4718)'\n",
      "  'POINT (8.423373333333334 55.4718)' ... 'POINT (8.42334 55.4718)'\n",
      "  'POINT (8.42334 55.4718)' 'POINT (8.42335 55.4718)']\n",
      " ['POINT EMPTY' 'POINT EMPTY' 'POINT EMPTY' ... 'POINT EMPTY'\n",
      "  'POINT EMPTY' 'POINT EMPTY']\n",
      " ...\n",
      " ['POINT EMPTY' 'POINT EMPTY' 'POINT EMPTY' ... 'POINT EMPTY'\n",
      "  'POINT EMPTY' 'POINT EMPTY']\n",
      " ['POINT EMPTY' 'POINT EMPTY' 'POINT EMPTY' ... 'POINT EMPTY'\n",
      "  'POINT EMPTY' 'POINT EMPTY']\n",
      " ['POINT EMPTY' 'POINT EMPTY' 'POINT EMPTY' ... 'POINT EMPTY'\n",
      "  'POINT EMPTY' 'POINT EMPTY']]\n",
      "<class 'numpy.ndarray'>\n",
      "5821\n",
      "(5821, 60)\n",
      "Process ended\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import multiprocessing\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_matrix(result_queue, begin_frame, end_frame, TIME_DELTA_SIZE, PERCENTAGE_OF_OBJECTS, x_min, y_min, x_max, y_max, timestamps, total_frames, GRANULARITY, ids_list):\n",
    "    p_start = timestamps[begin_frame]\n",
    "    p_end = timestamps[end_frame]\n",
    "    start_date = timestamps[0]\n",
    "    print(\"ok\")\n",
    "    connection_params = {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 5432,\n",
    "            \"dbname\": \"mobilitydb\",\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"postgres\"\n",
    "            }\n",
    "    table_name = \"pymeos_demo\"\n",
    "    id_column_name = \"mmsi\"\n",
    "    tpoint_column_name = \"trajectory\"               \n",
    "    connection = MobilityDB.connect(**connection_params)\n",
    "    \n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    ids_list = [ f\"'{id[0]}'\"  for id in ids_list]\n",
    "    ids_str = ', '.join(map(str, ids_list))\n",
    "\n",
    "    if GRANULARITY == \"SECOND\":\n",
    "        time_value = 1\n",
    "    elif GRANULARITY == \"MINUTE\":\n",
    "        time_value = 60\n",
    "    print(\"ok2\")\n",
    "    # return [self.tpoint_column_name, self.id_column_name, ids_str, xmin, ymin, xmax, ymax, pstart, pend, time_granularity, start_date, time_value]\n",
    "    query = f\"\"\"WITH trajectories as (\n",
    "            SELECT \n",
    "                atStbox(\n",
    "                    a.{tpoint_column_name}::tgeompoint,\n",
    "                    stbox(\n",
    "                        ST_MakeEnvelope(\n",
    "                            {x_min}, {y_min}, -- xmin, ymin\n",
    "                            {x_max}, {y_max}, -- xmax, ymax\n",
    "                            4326 -- SRID\n",
    "                        ),\n",
    "                        tstzspan('[{p_start}, {p_end}]')\n",
    "                    )\n",
    "                ) as trajectory\n",
    "            FROM public.{table_name} as a \n",
    "            WHERE a.{id_column_name} in ({ids_str})),\n",
    "\n",
    "            resampled as (\n",
    "\n",
    "            SELECT tsample(traj.trajectory, INTERVAL '1 {GRANULARITY}', TIMESTAMP '{start_date}')  AS resampled_trajectory\n",
    "                FROM \n",
    "                    trajectories as traj)\n",
    "        \n",
    "            SELECT\n",
    "                    EXTRACT(EPOCH FROM (startTimestamp(rs.resampled_trajectory) - '{start_date}'::timestamp))::integer / {time_value} AS start_index ,\n",
    "                    EXTRACT(EPOCH FROM (endTimestamp(rs.resampled_trajectory) - '{start_date}'::timestamp))::integer / {time_value} AS end_index,\n",
    "                    rs.resampled_trajectory\n",
    "            FROM resampled as rs ;\"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    print(\"ok3 rows\")\n",
    "    rows = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "       \n",
    "    empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "    \n",
    "\n",
    "    # now = time.time()\n",
    "    print(\"ok4 matrix\")\n",
    "    for i in range(len(rows)):\n",
    "        if rows[i][2] is not None:\n",
    "            try:\n",
    "                traj_resampled = rows[i][2]\n",
    "\n",
    "                start_index = rows[i][0] - begin_frame\n",
    "                end_index = rows[i][1] - begin_frame\n",
    "                values = np.array([point.wkt for point in traj_resampled.values()])\n",
    "                matrix[i, start_index:end_index+1] = values\n",
    "        \n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    result_queue.put(matrix)\n",
    "\n",
    "    \n",
    "\n",
    "# Using Manager's queue\n",
    "# manager = multiprocessing.Manager()\n",
    "result_queue = multiprocessing.Queue()\n",
    "\n",
    "# Creating and starting a new process to generate the matrix\n",
    "process = multiprocessing.Process(target=create_matrix, args=(result_queue, 60, 119, 60, 0.1, -180, -90, 180, 90, timestamps,len(timestamps), 'MINUTE',db.ids_list))\n",
    "process.start()\n",
    "# while(True):\n",
    "a = result_queue.get()\n",
    "print(a)\n",
    "print(type(a))\n",
    "print(len(a))\n",
    "print(a.shape)\n",
    "    \n",
    "process.join()  # Wait for the process to complete\n",
    "\n",
    "print(\"Process ended\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m process\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# while(True):\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mresult_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(a))\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:430\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 430\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:395\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import multiprocessing\n",
    "from shapely.geometry import Point\n",
    "def create_matrix(result_queue, begin_frame, end_frame, TIME_DELTA_SIZE, PERCENTAGE_OF_OBJECTS, x_min, y_min, x_max, y_max, timestamps, total_frames, GRANULARITY, db):\n",
    "    # a  =f\"all parameters : {begin_frame, end_frame, TIME_DELTA_SIZE, PERCENTAGE_OF_OBJECTS, x_min, y_min, x_max, y_max, len(timestamps), total_frames, GRANULARITY, db}\"\n",
    "    # result_queue.put(a)  \n",
    "    p_start = timestamps[begin_frame]\n",
    "    p_end = timestamps[end_frame]\n",
    "    # print(p_start, p_end, x_min, y_min, x_max, y_max)\n",
    "    # now_db = time.time()\n",
    "    \n",
    "\n",
    "\n",
    "    rows = db.get_subset_of_tpoints(p_start, p_end, x_min, y_min, x_max, y_max, GRANULARITY, start_date)    \n",
    "    # print(f\"Time to fetch subset of tpoints: {time.time() - now_db} seconds\\n\")\n",
    "            \n",
    "    empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "    \n",
    "\n",
    "    # now = time.time()\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        if rows[i][2] is not None:\n",
    "            try:\n",
    "                traj_resampled = rows[i][2]\n",
    "\n",
    "                start_index = rows[i][0] - begin_frame\n",
    "                end_index = rows[i][1] - begin_frame\n",
    "                values = np.array([point.wkt for point in traj_resampled.values()])\n",
    "                matrix[i, start_index:end_index+1] = values\n",
    "        \n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    result_queue.put(matrix)\n",
    "    \n",
    "\n",
    "# Using Manager's queue\n",
    "# manager = multiprocessing.Manager()\n",
    "result_queue = multiprocessing.Queue()\n",
    "\n",
    "# Creating and starting a new process to generate the matrix\n",
    "process = multiprocessing.Process(target=create_matrix, args=(result_queue, 0, 59, 60, 0.1, -180, -90, 180, 90, timestamps,len(timestamps), 'SECOND',db))\n",
    "process.start()\n",
    "# while(True):\n",
    "a = result_queue.get()\n",
    "print(a)\n",
    "print(type(a))\n",
    "print(len(a))\n",
    "print(a.shape)\n",
    "    \n",
    "process.join()  # Wait for the process to complete\n",
    "\n",
    "print(\"Process ended\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POINT EMPTY', 'POINT EMPTY', 'POINT EMPTY', ..., 'POINT EMPTY',\n",
       "       'POINT EMPTY', 'POINT EMPTY'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "def process_row(row):\n",
    "    # Example operation: Increment each element in the row\n",
    "    return row + 1\n",
    "\n",
    "def create_and_process_matrix():\n",
    "    # Step 2: Create a large matrix\n",
    "    rows, cols = 6000, 1440  # Example size\n",
    "    matrix = np.random.rand(rows, cols)\n",
    "    \n",
    "    # Step 3: Create a pool of workers and map process_row to each row\n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        # Apply process_row to each row of the matrix\n",
    "        # Note: pool.map expects a function that takes a single argument,\n",
    "        # so you might need to adapt if your function requires more.\n",
    "        result = pool.map(process_row, matrix)\n",
    "    \n",
    "    return np.array(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result_matrix = create_and_process_matrix()\n",
    "    print(\"Processed matrix shape:\", result_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'size' must be a positive number different from zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     shm\u001b[38;5;241m.\u001b[39munlink()  \u001b[38;5;66;03m# This removes the memory, ensure all processes are done using it\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m itemsize \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\u001b[38;5;241m.\u001b[39mitemsize\n\u001b[1;32m     27\u001b[0m size \u001b[38;5;241m=\u001b[39m itemsize \u001b[38;5;241m*\u001b[39m shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m shape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 28\u001b[0m shm \u001b[38;5;241m=\u001b[39m \u001b[43mshared_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSharedMemory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create a NumPy array backed by shared memory\u001b[39;00m\n\u001b[1;32m     31\u001b[0m matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray(shape, dtype\u001b[38;5;241m=\u001b[39mdifference_type, buffer\u001b[38;5;241m=\u001b[39mshm\u001b[38;5;241m.\u001b[39mbuf)\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/shared_memory.py:81\u001b[0m, in \u001b[0;36mSharedMemory.__init__\u001b[0;34m(self, name, create, size)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flags \u001b[38;5;241m=\u001b[39m _O_CREX \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mO_RDWR\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a positive number different from zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flags \u001b[38;5;241m&\u001b[39m os\u001b[38;5;241m.\u001b[39mO_EXCL:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m can only be None if create=True\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: 'size' must be a positive number different from zero"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import multiprocessing\n",
    "from multiprocessing import shared_memory\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def create_matrix(shm_name, shape):\n",
    "    # Access the existing shared memory block\n",
    "    existing_shm = shared_memory.SharedMemory(name=shm_name)\n",
    "    \n",
    "    # Create a NumPy array backed by shared memory\n",
    "    matrix = np.ndarray(shape, dtype=np.str_, buffer=existing_shm.buf)\n",
    "    \n",
    "    # Perform the operation to fill the matrix\n",
    "    empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    matrix.fill(empty_point_wkt)\n",
    "    print(\"Matrix shape:\", matrix.shape)\n",
    "    \n",
    "    # Clean up (memory will still exist, just detach from this process)\n",
    "    existing_shm.close()\n",
    "\n",
    "\n",
    "shape = (6000, 1440)\n",
    "\n",
    "# Calculate the size of the array and create shared memory\n",
    "dtype = np.str_\n",
    "itemsize = np.dtype(dtype).itemsize\n",
    "size = itemsize * shape[0] * shape[1]\n",
    "shm = shared_memory.SharedMemory(create=True, size=size)\n",
    "\n",
    "# Create a NumPy array backed by shared memory\n",
    "matrix = np.ndarray(shape, dtype=difference_type, buffer=shm.buf)\n",
    "matrix.fill('')  # Initialize with empty strings, can also use the actual initialization you need\n",
    "\n",
    "# Start the process that will modify the shared matrix\n",
    "process = multiprocessing.Process(target=create_matrix, args=(shm.name, shape))\n",
    "process.start()\n",
    "process.join()\n",
    "\n",
    "# Access the matrix from shared memory after the process completes\n",
    "result_matrix = np.ndarray(shape, dtype=difference_type, buffer=shm.buf)\n",
    "print(\"Processed matrix shape:\", result_matrix.shape)\n",
    "\n",
    "# Clean up shared memory\n",
    "shm.close()\n",
    "shm.unlink()  # This removes the memory, ensure all processes are done using it\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
