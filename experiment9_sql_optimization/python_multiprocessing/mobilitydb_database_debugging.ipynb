{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Include the PYQGIS imports for the plugin\n",
    "from pymeos.db.psycopg import MobilityDB\n",
    "from pymeos import *\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import deque\n",
    "from pympler import asizeof\n",
    "import gc\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import math\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "\n",
    "pymeos_initialize()\n",
    "DATABASE_NAME = \"mobilitydb\"\n",
    "TPOINT_TABLE_NAME = \"PyMEOS_demo\"\n",
    "TPOINT_ID_COLUMN_NAME = \"MMSI\"\n",
    "TPOINT_COLUMN_NAME = \"trajectory\"\n",
    "\n",
    "SRID = 4326\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_granularities = {\n",
    "                # \"MILLISECOND\" : timedelta(milliseconds=1),\n",
    "                    \"SECOND\" : timedelta(seconds=1),\n",
    "                    \"MINUTE\" : timedelta(minutes=1),\n",
    "                #   \"HOUR\" : timedelta(hours=1),\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database_connector:\n",
    "    \"\"\"\n",
    "    Singleton class used to connect to the MobilityDB database.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        try: \n",
    "            connection_params = {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 5432,\n",
    "            \"dbname\": DATABASE_NAME,\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"postgres\"\n",
    "            }\n",
    "            self.table_name = TPOINT_TABLE_NAME\n",
    "            self.id_column_name = TPOINT_ID_COLUMN_NAME\n",
    "            self.tpoint_column_name = TPOINT_COLUMN_NAME               \n",
    "            self.connection = MobilityDB.connect(**connection_params)\n",
    "\n",
    "            self.cursor = self.connection.cursor()\n",
    "\n",
    "            self.cursor.execute(f\"SELECT {self.id_column_name} FROM public.{self.table_name};\")\n",
    "            self.ids_list = self.cursor.fetchall()\n",
    "            self.ids_list = self.ids_list[:int(len(self.ids_list)*PERCENTAGE_OF_OBJECTS)]\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    def get_min_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the min timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            self.cursor.execute(f\"SELECT MIN(startTimestamp({self.tpoint_column_name})) AS earliest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    def get_max_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the max timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.cursor.execute(f\"SELECT MAX(endTimestamp({self.tpoint_column_name})) AS latest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    def get_subset_of_tpoints(self, pstart, pend, xmin, ymin, xmax, ymax, time_granularity, start_date):\n",
    "        \"\"\"\n",
    "        For each object in the ids_list :\n",
    "            Fetch the subset of the associated Tpoints between the start and end timestamps\n",
    "            contained in the STBOX defined by the xmin, ymin, xmax, ymax.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            ids_list = [ f\"'{id[0]}'\"  for id in self.ids_list]\n",
    "            ids_str = ', '.join(map(str, ids_list))\n",
    "\n",
    "            if time_granularity == \"SECOND\":\n",
    "                time_value = 1\n",
    "            elif time_granularity == \"MINUTE\":\n",
    "                time_value = 60\n",
    "            \n",
    "            # return [self.tpoint_column_name, self.id_column_name, ids_str, xmin, ymin, xmax, ymax, pstart, pend, time_granularity, start_date, time_value]\n",
    "            query = f\"\"\"WITH trajectories as (\n",
    "                    SELECT \n",
    "                        atStbox(\n",
    "                            a.{self.tpoint_column_name}::tgeompoint,\n",
    "                            stbox(\n",
    "                                ST_MakeEnvelope(\n",
    "                                    {xmin}, {ymin}, -- xmin, ymin\n",
    "                                    {xmax}, {ymax}, -- xmax, ymax\n",
    "                                    4326 -- SRID\n",
    "                                ),\n",
    "                                tstzspan('[{pstart}, {pend}]')\n",
    "                            )\n",
    "                        ) as trajectory\n",
    "                    FROM public.{self.table_name} as a \n",
    "                    WHERE a.{self.id_column_name} in ({ids_str})),\n",
    "\n",
    "                    resampled as (\n",
    "\n",
    "                    SELECT tsample(traj.trajectory, INTERVAL '1 {time_granularity}', TIMESTAMP '{start_date}')  AS resampled_trajectory\n",
    "                        FROM \n",
    "                            trajectories as traj)\n",
    "\t\t\t\t\n",
    "                    SELECT\n",
    "                            EXTRACT(EPOCH FROM (startTimestamp(rs.resampled_trajectory) - '{start_date}'::timestamp))::integer / {time_value} AS start_index ,\n",
    "                            EXTRACT(EPOCH FROM (endTimestamp(rs.resampled_trajectory) - '{start_date}'::timestamp))::integer / {time_value} AS end_index,\n",
    "                            rs.resampled_trajectory\n",
    "                    FROM resampled as rs ;\"\"\"\n",
    "        \n",
    "            self.cursor.execute(query)\n",
    "       \n",
    "            rows = self.cursor.fetchall()\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            print(query)\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close the connection to the MobilityDB database.\n",
    "        \"\"\"\n",
    "        self.cursor.close()\n",
    "        self.connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Database_connector()\n",
    "GRANULARITY = Time_granularities[\"MINUTE\"]\n",
    "start_date = db.get_min_timestamp()\n",
    "end_date = db.get_max_timestamp()\n",
    "total_frames = math.ceil( (end_date - start_date) // GRANULARITY )\n",
    "\n",
    "timestamps = [start_date + i * GRANULARITY for i in range(total_frames)]\n",
    "timestamps = [dt.replace(tzinfo=None) for dt in timestamps]\n",
    "timestamps_strings = [dt.strftime('%Y-%m-%d %H:%M:%S') for dt in timestamps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1439"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "<class 'numpy.ndarray'>\n",
      "10\n",
      "(10, 10)\n",
      "Process ended\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import multiprocessing\n",
    "from shapely.geometry import Point\n",
    "def create_matrix(result_queue, begin_frame, end_frame, TIME_DELTA_SIZE, PERCENTAGE_OF_OBJECTS, x_min, y_min, x_max, y_max, timestamps, total_frames, GRANULARITY, db):\n",
    "    # a  =f\"all parameters : {begin_frame, end_frame, TIME_DELTA_SIZE, PERCENTAGE_OF_OBJECTS, x_min, y_min, x_max, y_max, len(timestamps), total_frames, GRANULARITY, db}\"\n",
    "    # result_queue.put(a) \n",
    "\n",
    "    print(result_queue.get()) \n",
    "    # p_start = timestamps[begin_frame]\n",
    "    # p_end = timestamps[end_frame]\n",
    "    # # print(p_start, p_end, x_min, y_min, x_max, y_max)\n",
    "    # # now_db = time.time()\n",
    "    \n",
    "\n",
    "\n",
    "    # rows = db.get_subset_of_tpoints(p_start, p_end, x_min, y_min, x_max, y_max, GRANULARITY, start_date)    \n",
    "    # # print(f\"Time to fetch subset of tpoints: {time.time() - now_db} seconds\\n\")\n",
    "            \n",
    "    # empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    # matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "    \n",
    "\n",
    "    # # now = time.time()\n",
    "\n",
    "    # for i in range(len(rows)):\n",
    "    #     if rows[i][2] is not None:\n",
    "    #         try:\n",
    "    #             traj_resampled = rows[i][2]\n",
    "\n",
    "    #             start_index = rows[i][0] - begin_frame\n",
    "    #             end_index = rows[i][1] - begin_frame\n",
    "    #             values = np.array([point.wkt for point in traj_resampled.values()])\n",
    "    #             matrix[i, start_index:end_index+1] = values\n",
    "        \n",
    "    #         except:\n",
    "    #             continue\n",
    "    matrix = np.full((10, 10), 0, dtype=object)\n",
    "    result_queue.put(matrix)\n",
    "    \n",
    "\n",
    "# Using Manager's queue\n",
    "# manager = multiprocessing.Manager()\n",
    "result_queue = multiprocessing.Queue()\n",
    "result_queue.put(\"Hello\")\n",
    "# Creating and starting a new process to generate the matrix\n",
    "process = multiprocessing.Process(target=create_matrix, args=(result_queue, 0, 59, 60, 0.1, -180, -90, 180, 90, timestamps,len(timestamps), 'SECOND',db))\n",
    "process.start()\n",
    "# while(True):\n",
    "\n",
    "    \n",
    "process.join()  # Wait for the process to complete\n",
    "a = result_queue.get()\n",
    "print(a)\n",
    "print(type(a))\n",
    "print(len(a))\n",
    "print(a.shape)\n",
    "print(\"Process ended\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
