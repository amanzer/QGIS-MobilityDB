{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time deltas solution\n",
    "\n",
    "Current approach :\n",
    "\n",
    "For each time delta, data is stored in a large numpy matrix of size [t_delta_Frames x num_MMSI], 2 versions for calculating the position at each frame :\n",
    "1. Value_at_timestamp on each MMSI for each Frame of the time delta\n",
    "2. Time precision with Resampling of each MMSI_trajecotry, then simply replacing the corresponding arrays in the matrix\n",
    "\n",
    "These operations are done in Pymeos within the QGSThread, leading to a big framerate drop, with v2 being slighlty faster but with harder frame drop.\n",
    "\n",
    "\n",
    "\n",
    "Alternatives that we look at :\n",
    "\n",
    ". Perfom the temporal precision, resampling AND the indexes in the matrice in the mobilityDB database, this leads to longer times for fetching the matrix and automatically creates a wait time on new t delta\n",
    "\n",
    ". Instead of keeping a large matrix associated to all time deltas, only keep the tpoints and implement a iterable method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current implementation performance\n",
    "\n",
    "### Using Resampling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymeos.db.psycopg import MobilityDB\n",
    "from pymeos import *\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import deque\n",
    "from pympler import asizeof\n",
    "import gc\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "class Time_granularity(Enum):\n",
    "    MILLISECOND = {\"timedelta\" : timedelta(milliseconds=1)}\n",
    "    SECOND = {\"timedelta\" : timedelta(seconds=1)}\n",
    "    MINUTE = {\"timedelta\" : timedelta(minutes=1)}\n",
    "    HOUR = {\"timedelta\" : timedelta(hours=1)}\n",
    "  \n",
    "\n",
    "\n",
    "FPS_DEQUEUE_SIZE = 5 # Length of the dequeue to calculate the average FPS\n",
    "TIME_DELTA_DEQUEUE_SIZE =  10 # Length of the dequeue to keep the keys to keep in the buffer\n",
    "\n",
    "\n",
    "PERCENTAGE_OF_OBJECTS = 1 # To not overload the memory, we only take a percentage of the ships in the database\n",
    "TIME_DELTA_SIZE = 240 # Number of frames associated to one Time delta\n",
    "GRANULARITY = Time_granularity.MINUTE\n",
    "SRID = 4326\n",
    "FPS = 20\n",
    "\n",
    "\n",
    "class Database_connector:\n",
    "    \"\"\"\n",
    "    Singleton class used to connect to the MobilityDB database.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        try: \n",
    "            connection_params = {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 5432,\n",
    "            \"dbname\": \"mobilitydb\",\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"postgres\"\n",
    "            }\n",
    "            self.table_name = \"PyMEOS_demo\"\n",
    "            self.id_column_name = \"MMSI\"\n",
    "            self.tpoint_column_name = \"trajectory\"                    \n",
    "            self.connection = MobilityDB.connect(**connection_params)\n",
    "\n",
    "            self.cursor = self.connection.cursor()\n",
    "\n",
    "            self.cursor.execute(f\"SELECT {self.id_column_name} FROM public.{self.table_name};\")\n",
    "            self.ids_list = self.cursor.fetchall()\n",
    "            self.ids_list = self.ids_list[:int(len(self.ids_list)*PERCENTAGE_OF_OBJECTS)]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "  \n",
    "    def get_subset_of_tpoints(self, pstart, pend, xmin, ymin, xmax, ymax):\n",
    "        \"\"\"\n",
    "        For each object in the ids_list :\n",
    "            Fetch the subset of the associated Tpoints between the start and end timestamps\n",
    "            contained in the STBOX defined by the xmin, ymin, xmax, ymax.\n",
    "        \"\"\"\n",
    "        try:\n",
    "           \n",
    "            ids_list = [ f\"'{id[0]}'\"  for id in self.ids_list]\n",
    "            ids_str = ', '.join(map(str, ids_list))\n",
    "          \n",
    "            query = f\"\"\"\n",
    "                    SELECT \n",
    "                        atStbox(\n",
    "                            a.{self.tpoint_column_name}::tgeompoint,\n",
    "                            stbox(\n",
    "                                ST_MakeEnvelope(\n",
    "                                    {xmin}, {ymin}, -- xmin, ymin\n",
    "                                    {xmax}, {ymax}, -- xmax, ymax\n",
    "                                    4326 -- SRID\n",
    "                                ),\n",
    "                                tstzspan('[{pstart}, {pend}]')\n",
    "                            )\n",
    "                        )\n",
    "                    FROM public.{self.table_name} as a \n",
    "                    WHERE a.{self.id_column_name} in ({ids_str});\n",
    "                    \"\"\"\n",
    "            self.cursor.execute(query)\n",
    "            rows = self.cursor.fetchall()\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            self.log(e)\n",
    "\n",
    "\n",
    "    def get_min_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the min timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            self.cursor.execute(f\"SELECT MIN(startTimestamp({self.tpoint_column_name})) AS earliest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    def get_max_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the max timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.cursor.execute(f\"SELECT MAX(endTimestamp({self.tpoint_column_name})) AS latest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close the connection to the MobilityDB database.\n",
    "        \"\"\"\n",
    "        self.cursor.close()\n",
    "        self.connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTAGE_OF_OBJECTS = 1\n",
    "pymeos_initialize()\n",
    "db = Database_connector()\n",
    "\n",
    "x_min = -180\n",
    "y_min = -90\n",
    "x_max = 180\n",
    "y_max = 90\n",
    "start_date = db.get_min_timestamp()\n",
    "end_date = db.get_max_timestamp()\n",
    "total_frames = math.ceil( (end_date - start_date) // GRANULARITY.value[\"timedelta\"] )\n",
    "\n",
    "timestamps = [start_date + i * GRANULARITY.value[\"timedelta\"] for i in range(total_frames)]\n",
    "timestamps = [dt.replace(tzinfo=None) for dt in timestamps]\n",
    "timestamps_strings = [dt.strftime('%Y-%m-%d %H:%M:%S') for dt in timestamps]\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to fetch data for 0 - 240 : 2.975637674331665 s, time to create matrix : 0.04987382888793945 s, time to fill matrix : 11.17744255065918 s\n",
      "total time per time delta : 14.202954053878784 s\n"
     ]
    }
   ],
   "source": [
    "# Fetching the tpoints from the database\n",
    "now = time.time()\n",
    "\n",
    "begin_frame = 0\n",
    "end_frame = 240\n",
    "p_start = timestamps[begin_frame]\n",
    "p_end = timestamps[end_frame]\n",
    "rows = db.get_subset_of_tpoints(p_start, p_end, x_min, y_min, x_max, y_max)\n",
    "\n",
    "TIME_fetch_data = time.time() - now\n",
    "\n",
    "# Creating the matrix with empty points\n",
    "now = time.time()\n",
    "\n",
    "empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "\n",
    "TIME_create_matrix = time.time() - now\n",
    "\n",
    "# Filling the matrix using the resampling technique\n",
    "now = time.time()\n",
    "\n",
    "time_ranges = timestamps\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    try:\n",
    "        traj = rows[i][0]\n",
    "        traj = traj.temporal_precision(GRANULARITY.value[\"timedelta\"]) \n",
    "        num_instants = traj.num_instants()\n",
    "        if num_instants == 0:\n",
    "            continue\n",
    "        elif num_instants == 1:\n",
    "            single_timestamp = traj.timestamps()[0].replace(tzinfo=None)\n",
    "            index = time_ranges.index(single_timestamp) - begin_frame\n",
    "            matrix[i][index] = traj.values()[0].wkt\n",
    "        elif num_instants >= 2:\n",
    "            traj_resampled = traj.temporal_sample(start=time_ranges[0],duration= GRANULARITY.value[\"timedelta\"])\n",
    "            \n",
    "            start_index = time_ranges.index( traj_resampled.start_timestamp().replace(tzinfo=None) ) - begin_frame\n",
    "            end_index = time_ranges.index( traj_resampled.end_timestamp().replace(tzinfo=None) ) - begin_frame\n",
    "    \n",
    "            trajectory_array = np.array([point.wkt for point in traj_resampled.values()])\n",
    "            matrix[i, start_index:end_index+1] = trajectory_array\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "TIME_fill_matrix = time.time() - now\n",
    "\n",
    "print(f\"time to fetch data for {begin_frame} - {end_frame} : {TIME_fetch_data} s, time to create matrix : {TIME_create_matrix} s, time to fill matrix : {TIME_fill_matrix} s\")\n",
    "TIME_total = TIME_fetch_data + TIME_create_matrix + TIME_fill_matrix\n",
    "print(f\"total time per time delta : {TIME_total} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426.0886216163635"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30*TIME_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_deltas = [(0, 239), (240, 479), (480, 719), (720, 959), (960, 1199), (1200, 1438)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to fetch data for 0 - 239 : 3.2470123767852783 s, time to create matrix : 0.05280256271362305 s, time to fill matrix : 11.813145637512207 s\n",
      "total time per time delta : 15.112960577011108 s\n",
      "time to fetch data for 240 - 479 : 3.1140244007110596 s, time to create matrix : 0.057349205017089844 s, time to fill matrix : 12.651024580001831 s\n",
      "total time per time delta : 15.82239818572998 s\n",
      "time to fetch data for 480 - 719 : 3.3441922664642334 s, time to create matrix : 0.057309865951538086 s, time to fill matrix : 13.813710451126099 s\n",
      "total time per time delta : 17.21521258354187 s\n",
      "time to fetch data for 720 - 959 : 3.48903489112854 s, time to create matrix : 0.049497365951538086 s, time to fill matrix : 14.447538375854492 s\n",
      "total time per time delta : 17.98607063293457 s\n",
      "time to fetch data for 960 - 1199 : 3.086995840072632 s, time to create matrix : 0.05292940139770508 s, time to fill matrix : 12.314752340316772 s\n",
      "total time per time delta : 15.45467758178711 s\n",
      "time to fetch data for 1200 - 1438 : 2.958097457885742 s, time to create matrix : 0.04931759834289551 s, time to fill matrix : 10.725851058959961 s\n",
      "total time per time delta : 13.733266115188599 s\n"
     ]
    }
   ],
   "source": [
    "times_record_resampling = []\n",
    "for time_delta in time_deltas:\n",
    "    # Fetching the tpoints from the database\n",
    "    now = time.time()\n",
    "\n",
    "    begin_frame = time_delta[0]\n",
    "    end_frame = time_delta[1]\n",
    "    p_start = timestamps[begin_frame]\n",
    "    p_end = timestamps[end_frame]\n",
    "    rows = db.get_subset_of_tpoints(p_start, p_end, x_min, y_min, x_max, y_max)\n",
    "\n",
    "    TIME_fetch_data = time.time() - now\n",
    "\n",
    "    # Creating the matrix with empty points\n",
    "    now = time.time()\n",
    "\n",
    "    empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "\n",
    "    TIME_create_matrix = time.time() - now\n",
    "\n",
    "    # Filling the matrix using the resampling technique\n",
    "    now = time.time()\n",
    "   \n",
    "    time_ranges = timestamps\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        try:\n",
    "            traj = rows[i][0]\n",
    "            traj = traj.temporal_precision(GRANULARITY.value[\"timedelta\"]) \n",
    "            num_instants = traj.num_instants()\n",
    "            if num_instants == 0:\n",
    "                continue\n",
    "            elif num_instants == 1:\n",
    "                single_timestamp = traj.timestamps()[0].replace(tzinfo=None)\n",
    "                index = time_ranges.index(single_timestamp) - begin_frame\n",
    "                matrix[i][index] = traj.values()[0].wkt\n",
    "            elif num_instants >= 2:\n",
    "                traj_resampled = traj.temporal_sample(start=time_ranges[0],duration= GRANULARITY.value[\"timedelta\"])\n",
    "                \n",
    "                start_index = time_ranges.index( traj_resampled.start_timestamp().replace(tzinfo=None) ) - begin_frame\n",
    "                end_index = time_ranges.index( traj_resampled.end_timestamp().replace(tzinfo=None) ) - begin_frame\n",
    "        \n",
    "                trajectory_array = np.array([point.wkt for point in traj_resampled.values()])\n",
    "                matrix[i, start_index:end_index+1] = trajectory_array\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    TIME_fill_matrix = time.time() - now\n",
    "\n",
    "    print(f\"time to fetch data for {begin_frame} - {end_frame} : {TIME_fetch_data} s, time to create matrix : {TIME_create_matrix} s, time to fill matrix : {TIME_fill_matrix} s\")\n",
    "    TIME_total = TIME_fetch_data + TIME_create_matrix + TIME_fill_matrix\n",
    "    print(f\"total time per time delta : {TIME_total} s\")\n",
    "    times_record_resampling.append(TIME_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to fetch data : 15.887430946032206 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average time to fetch data : {sum([time_record for time_record in times_record_resampling])/len(times_record_resampling)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476.40000000000003"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many frames at 30 FPS needed for the animation\n",
    "15.88 * 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Value_at_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to fetch data for 0 - 240 : 2.9861526489257812 s, time to create matrix : 0.05749702453613281 s, time to fill matrix : 11.969017267227173 s\n",
      "total time per time delta : 15.012666940689087 s\n"
     ]
    }
   ],
   "source": [
    "# Fetching the tpoints from the database\n",
    "now = time.time()\n",
    "\n",
    "begin_frame = 0\n",
    "end_frame = 240\n",
    "p_start = timestamps[begin_frame]\n",
    "p_end = timestamps[end_frame]\n",
    "rows = db.get_subset_of_tpoints(p_start, p_end, x_min, y_min, x_max, y_max)\n",
    "\n",
    "TIME_fetch_data = time.time() - now\n",
    "\n",
    "# Creating the matrix with empty points\n",
    "now = time.time()\n",
    "\n",
    "empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "\n",
    "TIME_create_matrix = time.time() - now\n",
    "\n",
    "# Filling the matrix using the resampling technique\n",
    "now = time.time()\n",
    "\n",
    "time_ranges = timestamps\n",
    "\n",
    "for i in range(len(rows)):\n",
    "        for j in range(TIME_DELTA_SIZE):\n",
    "            try:\n",
    "                traj = rows[i][0]\n",
    "                try:\n",
    "                    coords = traj.value_at_timestamp(time_ranges[j + begin_frame])\n",
    "                    matrix[i][j] = coords.wkt\n",
    "                except:\n",
    "                    continue\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "TIME_fill_matrix = time.time() - now\n",
    "\n",
    "print(f\"time to fetch data for {begin_frame} - {end_frame} : {TIME_fetch_data} s, time to create matrix : {TIME_create_matrix} s, time to fill matrix : {TIME_fill_matrix} s\")\n",
    "TIME_total = TIME_fetch_data + TIME_create_matrix + TIME_fill_matrix\n",
    "print(f\"total time per time delta : {TIME_total} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450.3800082206726"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30*TIME_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to fetch data for 0 - 239 : 3.1740968227386475 s, time to create matrix : 0.04974675178527832 s, time to fill matrix : 12.176667928695679 s\n",
      "total time per time delta : 15.400511503219604 s\n",
      "time to fetch data for 240 - 479 : 3.097400188446045 s, time to create matrix : 0.05050015449523926 s, time to fill matrix : 13.664529085159302 s\n",
      "total time per time delta : 16.812429428100586 s\n",
      "time to fetch data for 480 - 719 : 3.3440070152282715 s, time to create matrix : 0.054293155670166016 s, time to fill matrix : 14.504016637802124 s\n",
      "total time per time delta : 17.90231680870056 s\n",
      "time to fetch data for 720 - 959 : 3.269920587539673 s, time to create matrix : 0.0589900016784668 s, time to fill matrix : 14.912182092666626 s\n",
      "total time per time delta : 18.241092681884766 s\n",
      "time to fetch data for 960 - 1199 : 3.1655845642089844 s, time to create matrix : 0.060967206954956055 s, time to fill matrix : 13.672136068344116 s\n",
      "total time per time delta : 16.898687839508057 s\n",
      "time to fetch data for 1200 - 1438 : 2.985629081726074 s, time to create matrix : 0.06614112854003906 s, time to fill matrix : 11.554495811462402 s\n",
      "total time per time delta : 14.606266021728516 s\n"
     ]
    }
   ],
   "source": [
    "times_record_vat = []\n",
    "for time_delta in time_deltas:\n",
    "    # Fetching the tpoints from the database\n",
    "    now = time.time()\n",
    "\n",
    "    begin_frame = time_delta[0]\n",
    "    end_frame = time_delta[1]\n",
    "    p_start = timestamps[begin_frame]\n",
    "    p_end = timestamps[end_frame]\n",
    "    rows = db.get_subset_of_tpoints(p_start, p_end, x_min, y_min, x_max, y_max)\n",
    "\n",
    "    TIME_fetch_data = time.time() - now\n",
    "\n",
    "    # Creating the matrix with empty points\n",
    "    now = time.time()\n",
    "\n",
    "    empty_point_wkt = Point().wkt  # \"POINT EMPTY\"\n",
    "    matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point_wkt, dtype=object)\n",
    "\n",
    "    TIME_create_matrix = time.time() - now\n",
    "\n",
    "    # Filling the matrix using the resampling technique\n",
    "    now = time.time()\n",
    "   \n",
    "    time_ranges = timestamps\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "            for j in range(TIME_DELTA_SIZE):\n",
    "                try:\n",
    "                    traj = rows[i][0]\n",
    "                    try:\n",
    "                        coords = traj.value_at_timestamp(time_ranges[j + begin_frame])\n",
    "                        matrix[i][j] = coords.wkt\n",
    "                    except:\n",
    "                        continue\n",
    "                except:\n",
    "                    continue\n",
    "              \n",
    "    TIME_fill_matrix = time.time() - now\n",
    "\n",
    "    print(f\"time to fetch data for {begin_frame} - {end_frame} : {TIME_fetch_data} s, time to create matrix : {TIME_create_matrix} s, time to fill matrix : {TIME_fill_matrix} s\")\n",
    "    TIME_total = TIME_fetch_data + TIME_create_matrix + TIME_fill_matrix\n",
    "    print(f\"total time per time delta : {TIME_total} s\")\n",
    "    times_record_vat.append(TIME_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'average time to fetch data : 16.643550713857014 s'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"average time to fetch data : {sum([time_record for time_record in times_record_vat])/len(times_record_vat)} s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499.20000000000005"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many frames at 30 FPS needed for the animation\n",
    "16.64 * 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the resampling and indexing for matrix inside the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymeos.db.psycopg import MobilityDB\n",
    "from pymeos import *\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from collections import deque\n",
    "from pympler import asizeof\n",
    "import gc\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "class Time_granularity(Enum):\n",
    "    MILLISECOND = {\"timedelta\" : timedelta(milliseconds=1)}\n",
    "    SECOND = {\"timedelta\" : timedelta(seconds=1)}\n",
    "    MINUTE = {\"timedelta\" : timedelta(minutes=1)}\n",
    "    HOUR = {\"timedelta\" : timedelta(hours=1)}\n",
    "  \n",
    "\n",
    "\n",
    "FPS_DEQUEUE_SIZE = 5 # Length of the dequeue to calculate the average FPS\n",
    "TIME_DELTA_DEQUEUE_SIZE =  10 # Length of the dequeue to keep the keys to keep in the buffer\n",
    "\n",
    "\n",
    "PERCENTAGE_OF_OBJECTS = 1 # To not overload the memory, we only take a percentage of the ships in the database\n",
    "TIME_DELTA_SIZE = 240 # Number of frames associated to one Time delta\n",
    "GRANULARITY = Time_granularity.MINUTE\n",
    "SRID = 4326\n",
    "FPS = 20\n",
    "\n",
    "\n",
    "class Database_connector_2:\n",
    "    \"\"\"\n",
    "    Singleton class used to connect to the MobilityDB database.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        try: \n",
    "            connection_params = {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 5432,\n",
    "            \"dbname\": \"mobilitydb\",\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"postgres\"\n",
    "            }\n",
    "            self.table_name = \"PyMEOS_demo\"\n",
    "            self.id_column_name = \"MMSI\"\n",
    "            self.tpoint_column_name = \"trajectory\"                    \n",
    "            self.connection = MobilityDB.connect(**connection_params)\n",
    "\n",
    "            self.cursor = self.connection.cursor()\n",
    "\n",
    "            self.cursor.execute(f\"SELECT {self.id_column_name} FROM public.{self.table_name};\")\n",
    "            self.ids_list = self.cursor.fetchall()\n",
    "            self.ids_list = self.ids_list[:int(len(self.ids_list)*PERCENTAGE_OF_OBJECTS)]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "  \n",
    "    def get_subset_of_tpoints(self, pstart, pend, xmin, ymin, xmax, ymax):\n",
    "        \"\"\"\n",
    "        For each object in the ids_list :\n",
    "            Fetch the subset of the associated Tpoints between the start and end timestamps\n",
    "            contained in the STBOX defined by the xmin, ymin, xmax, ymax.\n",
    "        \"\"\"\n",
    "        try:\n",
    "           \n",
    "            ids_list = [ f\"'{id[0]}'\"  for id in self.ids_list]\n",
    "            ids_str = ', '.join(map(str, ids_list))\n",
    "          \n",
    "            query = f\"\"\"\n",
    "                    -- Resampling trajectories to 1 minute intervals\n",
    "                    WITH trajectories AS (\n",
    "                        SELECT \n",
    "                            MMSI,\n",
    "                            atStbox(\n",
    "                                a.trajectory::tgeompoint,\n",
    "                                stbox(\n",
    "                                     ST_MakeEnvelope(\n",
    "                                    {xmin}, {ymin}, -- xmin, ymin\n",
    "                                    {xmax}, {ymax}, -- xmax, ymax\n",
    "                                    4326 -- SRID\n",
    "                                ),\n",
    "                                tstzspan('[{pstart}, {pend}]')\n",
    "                                )\n",
    "                            ) as traj\n",
    "                        FROM public.PyMEOS_demo as a \n",
    "                        WHERE a.{self.id_column_name} in ({ids_str})),\n",
    "                    processed_trajectory AS (\n",
    "                        SELECT \n",
    "                            tprecision(traj, INTERVAL '1 minute', startTimestamp(traj)) AS precise_trajectory\n",
    "                        FROM \n",
    "                            trajectories \n",
    "                    ),\n",
    "                        \n",
    "                    resampled AS \n",
    "                            (SELECT \n",
    "                                tsample(precise_trajectory, INTERVAL '1 minute', startTimestamp(precise_trajectory))  AS resampled_trajectory\n",
    "                                FROM \n",
    "                                processed_trajectory\n",
    "                                ),\n",
    "                        \n",
    "\n",
    "                        final_values AS (\n",
    "                    SELECT\n",
    "                        startTimestamp(resampled_trajectory) as start_timestamp, endTimestamp(resampled_trajectory) as end_timestamp,\n",
    "                        resampled_trajectory \n",
    "                    FROM \n",
    "                        resampled\n",
    "                    ),\n",
    "\n",
    "                    -- Resampling trajectories to 1 minute intervals\n",
    "                    minute_intervals AS (\n",
    "                        SELECT \n",
    "                            generate_series(\n",
    "                                timestamp '{pstart}', \n",
    "                                timestamp '{pend}', \n",
    "                                interval '1 minute'\n",
    "                            ) AS ts\n",
    "                    ),\n",
    "                    timestamps_with_index AS (\n",
    "                        SELECT \n",
    "                            ts,\n",
    "                            row_number() OVER (ORDER BY ts) - 1 AS idx  \n",
    "                        FROM \n",
    "                            minute_intervals\n",
    "                    ),\n",
    "                        \n",
    "                    start_end_indices AS (\n",
    "                        SELECT \n",
    "                            MIN(t.idx) AS start_index,\n",
    "                            MAX(g.idx) AS end_index,\n",
    "                            p.resampled_trajectory as traj\n",
    "                        FROM \n",
    "                            final_values p\n",
    "                        JOIN \n",
    "                            timestamps_with_index t ON t.ts = p.start_timestamp\n",
    "                        JOIN \n",
    "                            timestamps_with_index g ON g.ts = p.end_timestamp\n",
    "                        GROUP BY\n",
    "                        p.resampled_trajectory\n",
    "\n",
    "                    )\n",
    "\n",
    "                    SELECT\n",
    "                        start_index,\n",
    "                        end_index,\n",
    "                        traj\n",
    "                        \n",
    "                        \n",
    "                    FROM\n",
    "                        start_end_indices;\n",
    "\n",
    "\n",
    "                    \"\"\"\n",
    "\n",
    "            self.cursor.execute(query)\n",
    "            rows = self.cursor.fetchall()\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching the subset of Tpoints : {e}\")\n",
    "\n",
    "\n",
    "    def get_min_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the min timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            self.cursor.execute(f\"SELECT MIN(startTimestamp({self.tpoint_column_name})) AS earliest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    def get_max_timestamp(self):\n",
    "        \"\"\"\n",
    "        Returns the max timestamp of the tpoints columns.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.cursor.execute(f\"SELECT MAX(endTimestamp({self.tpoint_column_name})) AS latest_timestamp FROM public.{self.table_name};\")\n",
    "            return self.cursor.fetchone()[0]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close the connection to the MobilityDB database.\n",
    "        \"\"\"\n",
    "        self.cursor.close()\n",
    "        self.connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTAGE_OF_OBJECTS = 1\n",
    "pymeos_initialize()\n",
    "db = Database_connector_2()\n",
    "\n",
    "x_min = -180\n",
    "y_min = -90\n",
    "x_max = 180\n",
    "y_max = 90\n",
    "start_date = db.get_min_timestamp()\n",
    "end_date = db.get_max_timestamp()\n",
    "total_frames = math.ceil( (end_date - start_date) // GRANULARITY.value[\"timedelta\"] )\n",
    "\n",
    "timestamps = [start_date + i * GRANULARITY.value[\"timedelta\"] for i in range(total_frames)]\n",
    "timestamps = [dt.replace(tzinfo=None) for dt in timestamps]\n",
    "timestamps_strings = [dt.strftime('%Y-%m-%d %H:%M:%S') for dt in timestamps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to fetch data for 0 - 239 : 7.0551979541778564 s, time to create matrix : 0.002498149871826172 s, time to fill matrix : 0.304271936416626 s\n",
      "total time per time delta : 7.361968040466309 s\n",
      "150\n",
      "time to fetch data for 240 - 479 : 18.673765182495117 s, time to create matrix : 0.021819114685058594 s, time to fill matrix : 10.037767171859741 s\n",
      "total time per time delta : 28.733351469039917 s\n",
      "3433\n",
      "time to fetch data for 480 - 719 : 21.429890632629395 s, time to create matrix : 0.12171459197998047 s, time to fill matrix : 9.839786767959595 s\n",
      "total time per time delta : 31.39139199256897 s\n",
      "3809\n",
      "time to fetch data for 720 - 959 : 20.870601415634155 s, time to create matrix : 0.15086674690246582 s, time to fill matrix : 10.00284194946289 s\n",
      "total time per time delta : 31.02431011199951 s\n",
      "3981\n",
      "time to fetch data for 960 - 1199 : 19.214648962020874 s, time to create matrix : 0.1467278003692627 s, time to fill matrix : 8.770018577575684 s\n",
      "total time per time delta : 28.13139533996582 s\n",
      "3832\n",
      "time to fetch data for 1200 - 1438 : 18.285633087158203 s, time to create matrix : 0.13548803329467773 s, time to fill matrix : 7.702618598937988 s\n",
      "total time per time delta : 26.12373971939087 s\n",
      "3286\n"
     ]
    }
   ],
   "source": [
    "times_record_db_resampling = []\n",
    "for time_delta in time_deltas:\n",
    "    # Fetching the tpoints from the database\n",
    "    now = time.time()\n",
    "\n",
    "    begin_frame = time_delta[0]\n",
    "    end_frame = time_delta[1]\n",
    "    p_start = timestamps[begin_frame]\n",
    "    p_end = timestamps[end_frame]\n",
    "    rows = db.get_subset_of_tpoints(p_start, p_end, x_min, y_min, x_max, y_max)\n",
    "\n",
    "    TIME_fetch_data = time.time() - now\n",
    "\n",
    "    # Creating the matrix with empty points\n",
    "    now = time.time()\n",
    "\n",
    "    empty_point = Point()  # \"POINT EMPTY\"\n",
    "    matrix = np.full((len(rows), TIME_DELTA_SIZE), empty_point, dtype=object)\n",
    "\n",
    "    TIME_create_matrix = time.time() - now\n",
    "\n",
    "    # Filling the matrix using the resampling technique\n",
    "    now = time.time()\n",
    "\n",
    "    count= 0\n",
    "    for i in range(len(rows)):\n",
    "        try:\n",
    "            traj = rows[i][2]\n",
    "\n",
    "            start_index = rows[i][0]\n",
    "            end_index = rows[i][1]\n",
    "\n",
    "            # trajectory_array = np.array([point.wkt for point in traj.values()])\n",
    "            matrix[i, start_index:end_index+1] = traj.values()\n",
    "            count +=1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    TIME_fill_matrix = time.time() - now\n",
    "\n",
    "    print(f\"time to fetch data for {begin_frame} - {end_frame} : {TIME_fetch_data} s, time to create matrix : {TIME_create_matrix} s, time to fill matrix : {TIME_fill_matrix} s\")\n",
    "    TIME_total = TIME_fetch_data + TIME_create_matrix + TIME_fill_matrix\n",
    "    print(f\"total time per time delta : {TIME_total} s\")\n",
    "    times_record_db_resampling.append(TIME_total)\n",
    "    print(count)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_record_db_resampling = times_record_db_resampling[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'average time to fetch data : 29.080837726593018 s'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"average time to fetch data : {sum([time_record for time_record in times_record_db_resampling])/len(times_record_db_resampling)} s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872.4"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many frames at 30 FPS needed for the animation\n",
    "29.08 * 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try/except clause vs if statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triggering clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.74 ms ± 13.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = [i for i in range(100000)]\n",
    "\n",
    "idx = 1e7\n",
    "if idx > len(a) or idx < 0 :\n",
    "    #some operation\n",
    "    average = sum(a)/len(a)\n",
    "else:\n",
    "    a[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.74 ms ± 14.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = [i for i in range(100000)]\n",
    "\n",
    "idx = 1e7\n",
    "try:\n",
    "    a[idx]\n",
    "except:\n",
    "    average = sum(a)/len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without triggering clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22 ms ± 61.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = [i for i in range(100000)]\n",
    "\n",
    "idx = 10\n",
    "if idx > len(a) or idx < 0 :\n",
    "    #some operation\n",
    "    average = sum(a)/len(a)\n",
    "else:\n",
    "    a[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19 ms ± 29.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = [i for i in range(100000)]\n",
    "\n",
    "idx = 10\n",
    "try:\n",
    "    a[idx]\n",
    "except:\n",
    "    average = sum(a)/len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionnary update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POINT (0 0)', 'POINT (0 0)', 'POINT (0 0)', ..., 'POINT (0 0)',\n",
       "       'POINT (0 0)', 'POINT (0 0)'], dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "array = np.full(5000, Point(0,0).wkt, dtype=object)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 µs ± 6.63 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "dict1 = {}\n",
    "for i in range(5000):\n",
    "    dict1[i] = array[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 µs ± 4.59 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "dict2 = dict(zip(range(5000), array))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
